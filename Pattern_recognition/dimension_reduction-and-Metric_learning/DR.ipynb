{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降维    \n",
    "  高维空间带来的问题：  \n",
    "  * 1、样本稀疏：  \n",
    "  在KNN中我们假设了如果样本足够密，就能有很好的预测效果。然而在现实中我们不可能取得如此多得训练样本。  \n",
    "  $\\delta=0.001;$在一维的情况下：假设属性为x:那么把属性的取值归一化后，也就是让x的取值范围维\\[0-1\\];那么在\\[0-1\\]就需要有1000个   样本才能满足要求；在二维情况下：就需要有$1000 \\times 1000 =（10^3）^2$个样本；在10维的时候就需要$1000 \\times 1000 =（10^3）     ^{10}$个样本，而实际中我们属性数目远多于10个，所以我们实际不可能找到那么多的样本。  \n",
    "    \n",
    "   (维度增加时，空间的体积增加得很快，使得可用的数据变得稀疏。稀疏性对于任何要求有统计学意义的方法而言都是一个问题，为了获得在统计学上正确并且有可靠的结果，用来支撑这一结果所需要的数据量通常随着维数的提高而呈指数级增长。而且，在组织和搜索数据时也有赖于检测对象区域，这些区域中的对象通过相似度属性而形成分组。然而在高维空间中，所有的数据都很稀疏，从很多角度看都不相似，因而平常使用的数据组织策略变得极其低效)  \n",
    "     \n",
    "   <br>  \n",
    "    \n",
    "  * 2、距离计算困难：   \n",
    "  距离函数：超球体的半径r ,维数为d ，超立方体边长为2r   \n",
    "    \n",
    "    $\\Gamma(x)$函数：$\\Gamma(x)=\\int_0^{+\\infty}t^{x-1}e^{-t}dt(x >0)$\n",
    "  \n",
    "  3维欧几里球体体积：$\\frac{4\\pi r^3 2^3}{3}\\quad$  ;多维超球体：欧几里得距离：$\\frac{2r^d\\pi^{\\frac{d}{2}}}{d\\Gamma(d/2)}\\qquad$超立方体欧几里得距离：$(2r)^d$  \n",
    "    \n",
    "  当维数过高时，相对立方体的体积，其内接球的体积几乎可以忽略不记；这也说明了距离在高维空间不再有辨识度。  \n",
    "    \n",
    "  从超立体的超内接球体积极为小；可以得出一般的结论，，几乎所有的高维空间都远离其中心。  \n",
    "    \n",
    "  当维数越高，几乎空间中的所有点到中心距离的最大值和最小值几乎相同；这也说明了距离在高维空间不再有辨识度  \n",
    "    \n",
    "  $\\underset{d \\rightarrow +\\infty}{\\lim} \\frac{d_{max}\\;-\\;d_{min}}{d_{min}}\\rightarrow 0$  \n",
    "    \n",
    "  <br>  \n",
    "  \n",
    "  (因此，在某种意义上，几乎所有的高维空间都远离其中心，或者从另一个角度来看，高维单元空间可以说是几乎完全由超立方体的“边角”所组成的，没有“中部”，这对于理解卡方分布是很重要的直觉理解。 给定一个单一分布，由于其最小值和最大值与最小值相比收敛于0，因此，其最小值和最大值的距离变得不可辨别。)  \n",
    "    \n",
    "  (因此，在高维空间用距离来衡量样本相似性的方法已经渐渐失效。所以以距离为标准的分类算法（欧氏距离，曼哈顿距离，马氏距离）在低维空间会有更好的表现。类似的，高斯分布在高维空间会变得更加平坦，而且尾巴也会更长。\n",
    "对于使用距离测度的机器学习算法的影响：\n",
    "由于维度灾难的影响，正如前面所说的在高维空间中，欧式距离的测度会失去意义，当维度趋于无穷时，数据集中任意两点的距离会趋向收敛，意思是任意两点的最大距离和最小距离会变为相同。\n",
    "因此基于欧式距离的k-means算法，会无法进行聚类（因为距离会趋于收敛）。而K-NN会的临近K个点中，会出现更多非同类的点（远多于低维度的情况）  \n",
    "  \n",
    "    \n",
    "基于以上两种情况得出再高维空间带来的各种问题称为维数灾难；正是由于维数灾难我们才要降维处理。    \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    " <br>\n",
    " <br>  \n",
    " \n",
    "    \n",
    "    \n",
    "### 低维嵌入\n",
    "\n",
    "一方面找不到满足密度采样要求的数据集；另一方面在高维的情况下，计算样本距离是困难的。所以使用降维来缓解维数灾难。  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "降维：通过某种数学变换，将高维属性空间，变为低维子空间；在这个子空间中样本密度大幅度提高，距离计算也变得更容易。  \n",
    "  \n",
    "$\\qquad$虽然人们观察到样本属性是高维的，但是与我们学习任务相关的可能只是某一些属性而不是全部属性。也就是高维空间的一个低维嵌入。    \n",
    "\n",
    " <br>  \n",
    " \n",
    "    \n",
    "*  多维缩放（MDS）：  \n",
    "一种经典的降维方法，能够使在高维空间中样本之间的距离在低维空间中得以保持。  \n",
    "    \n",
    "  假设m个样本在原始空间中距离矩阵为为：$D \\in R^{m \\times m}$  \n",
    "     \n",
    "  目标是：是获得m个样本在低维子空间的表示$Z \\in R^{d^{'} \\times m}$ 且在子空间的距离矩阵不变也为$D \\in R^{m \\times m}$  \n",
    "    \n",
    "  $B=Z^TZ \\quad$B为内积矩阵 $b_{ij}=z_i^Tz_j  \\qquad$为了后面方便讨论，对降维样本中心化即$\\sum_{i=1}^mz_i=0 \\quad$那么对B有$\\sum_{i=1}^mb_{ij}=\\sum_{i=1}^mb_{ji}=0$   \n",
    "  \n",
    "   两样本之间的距离为：$dist_{ij}^2=||z_i||^2+||z_j||^2-2z_i^Tz_j  \\;=\\; b_{ii}+b_{jj}-2b_{ij}$   \n",
    "     \n",
    "   所以根据$\\sum_{i=1}^mz_i=0 \\quad tr(B)=\\sum_{i=1}^mb_{ii}$有：  \n",
    "     \n",
    "    $\\sum_{i=1}^mdist_{ij}^2=tr(B)+mb_{jj}$  \n",
    "      \n",
    "    $\\sum_{j=1}^mdist_{ij}^2=tr(B)+mb_{ii}$  \n",
    "      \n",
    "    $\\sum_{i=1}^m\\sum_{j=1}^mdist_{ij}^2=tr(B)+tr(B)$  \n",
    "          \n",
    "   重新令：$dist_{i\\cdot}^2$ ：  \n",
    "   $dist_{i\\cdot}^2=\\frac{1}{m}\\sum_{j=1}^m dist_{ij}^2$  \n",
    "     \n",
    "   $dist_{\\cdot j}^2=\\frac{1}{m}\\sum_{j=1}^m dist_{ij}^2$  \n",
    "     \n",
    "   $dist_{\\cdot \\cdot}^2=\\frac{1}{m^2}\\sum_{i=1}^m \\sum_{j=1}^m dist_{ij}^2$  \n",
    "     \n",
    "   结合以上公式可以推导出:$b_{ij}=-\\frac{1}{2}(dist_{ij}^2-dist_{\\cdot j}^2-dist_{i\\cdot}^2+dist_{\\cdot\\cdot}^2)$  \n",
    "     \n",
    "   得到这个式子，就可以明显看出，在原始空间样本距离矩阵不变的情况下，可以求出降维后的样本表示矩阵的内积矩阵B。（降维矩阵Z的距离矩阵也是D）  \n",
    "     \n",
    "   此时已经求出了B;而$B=Z^TZ \\qquad $ ；求出B之后，只要对B做特征分解，就可以求出Z;$\\;\\; B=\\bigvee\\bigwedge\\bigvee^T$那么$z=\\bigwedge^{\\frac{1}{2}}\\bigvee^T$     \n",
    "     \n",
    "   其中：$\\bigwedge$是特征值，组成的对角矩阵，$\\bigvee$是特征向量组成的矩阵。  \n",
    "     \n",
    "   多维缩放：主要是根据原始空间样本距离矩阵，求低维子空间的样本的内积矩阵，在通过特征值分解这个内积矩阵，来求出低维样本矩阵。 \n",
    "     \n",
    "    \n",
    "      \n",
    " <br>  \n",
    " <br>  \n",
    " \n",
    " ### 主成分析（PCA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
