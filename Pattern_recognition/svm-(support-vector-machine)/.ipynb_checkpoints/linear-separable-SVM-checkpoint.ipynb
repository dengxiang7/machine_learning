{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性可分下的支持向量机\n",
    "#### 什么是最优分类\n",
    "对线性可分样本，我们所得到的决策面，对未见样本有很好容错性。  \n",
    "<img src=\"../../img/Pattern_recognition/linear-spe-svm/optimization-spe1.PNG\" />  \n",
    "  \n",
    "<br>\n",
    "\n",
    "#### 线性可分条件下的SVM\n",
    "样本集：  \n",
    "$\\quad \\{(x_1,y_1),(x_2,y_2),{\\cdots},(x_i,y_i),{\\cdots}\\} \\qquad\\quad x_i \\in R^d \\quad y_i\\{-1,+1\\}$  \n",
    "  \n",
    "存在超平面能将样本无错分开：  \n",
    "$\\qquad \\qquad \\quad\n",
    "        \\left.\n",
    "        \\begin{array}{l}\n",
    "        W^TX_i+b >0\\;\\;if \\quad y_i=1 \\\\\n",
    "          W^TX_i+b <0\\;\\;if \\quad y_i=-1\\\\\n",
    "        \\end{array}\n",
    "        \\right\\}\n",
    "          .\n",
    "$   \n",
    "  \n",
    "  分类间隔：  \n",
    "所有样本点到决策面距离的最小值：$\\underset {i=1,2，\\cdots}{min}\\frac{|W^TX_i+b|}{||W||} \\quad $注意这个分类间隔是超平面两侧的距离。  \n",
    "  \n",
    "    \n",
    " #### 最优超平面的确定过程  \n",
    " 首先明确：对于线性可分样本，存在很多超平面能够把样本分类。而其中最优超平面有很好容纳性，目标就是找到这个最优超平面。  \n",
    "   \n",
    " 目标: 寻找超平面WTX+b使所有样本线性可分，且这个超平面是最优超平面  \n",
    "   \n",
    "\n",
    " \n",
    " \n",
    "过程： \n",
    "<br>  \n",
    "   <img src=\"../../img/Pattern_recognition/linear-spe-svm/guocheng1.PNG\" />   \n",
    " \n",
    "1.找超平面的过程中，确定一个超平面H1,求所有样本到H1的最小距离样本，把这个距离视为分类间隔，要有最好的容纳性，则最小的距离应该最大，而H1的分类间隔$d_1$，不一定是所有超平面中最大分类间隔；明显$d_1$还可以继续大  \n",
    " \n",
    " <img src=\"../../img/Pattern_recognition/linear-spe-svm/guocheng2.PNG\" />   \n",
    "\n",
    "2.此时H就是最优超平面;找不到其他分类间隔更大了 。最短距离样本的分类间隔:是超平面两侧在这个距离内都没有样本。  \n",
    "  \n",
    "如此可得到最优超平面的计算方式：  \n",
    "  \n",
    "$\\quad\\quad  \\underset{w,b}{max} \\;\\;\\underset {i=1,2，\\cdots}{min}\\frac{|W^TX_i+b|}{||W||} $  \n",
    "$\\quad\\quad\\qquad  s.t. y_i(w^Tx_i+b)>0 \\quad i=1,2，\\cdots$  \n",
    "  \n",
    "这个意思是：找到某个超平面，这个超平面能把样本完全分类正确且拥有最大分类间隔。  \n",
    "    \n",
    "<br>\n",
    "上述这个优化目标不失一般性的等价于:  \n",
    "\n",
    "$\\qquad\\quad  \\underset{w,b}{min} \\;\\;{||W||}^2 $  \n",
    "\n",
    "$\\quad\\quad\\qquad  s.t. y_i(w^Tx_i+b)\\geq 1 \\quad i=1,2，\\cdots$  \n",
    "  \n",
    "这时变成了凸规化使用拉格朗日乘子法：  \n",
    "$\\qquad \\qquad \\quad L(w，b,\\lambda)={||W||}^2+\\sum_{i=1}^n\\lambda_i (1- y_i(w^Tx_i+b))$   求这个无约束问题的极值问题。  \n",
    "  \n",
    "  \n",
    "但是这个无约束的极值需要满足如下条件：  \n",
    "\n",
    "$\\qquad \\qquad \\quad\n",
    "        \\left.\n",
    "        \\begin{array}{l}\n",
    "        \\frac{\\partial L(w，b,\\lambda)}{\\partial w}=0 \\quad \\Rightarrow  w-\\sum_{i=1}^n \\lambda_i y_i x_i =0\\\\\n",
    "        \\frac {\\partial L(w，b,\\lambda)}{\\partial b}=0 \\quad \\Rightarrow  \\sum_{i=1}^n \\lambda_i y_i =0\\\\\n",
    "        1- y_i(w^Tx_i+b)\\leq \\;0  \\\\\n",
    "        \\lambda_i \\geq \\;0  \\\\\n",
    "        \\lambda_i (1- y_i(w^Tx_i+b)= \\;0 \\\\\n",
    "        \\end{array}\n",
    "        \\right\\}\n",
    "        = \\;\\;\\;为KKT \\;条件\n",
    "$  \n",
    "  \n",
    "<br>    \n",
    "这时有很多样本，解这个满足KKT条件的无约束极值任然很麻烦；所以使用对偶问题来求解：  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "原问题：  \n",
    "$\\qquad\\quad  \\underset{w,b}{min} \\;\\;{||W||}^2 $  \n",
    "\n",
    "$\\quad\\quad\\qquad  s.t. y_i(w^Tx_i+b)\\geq 1 \\quad i=1,2，\\cdots$   \n",
    " \n",
    "<br>  \n",
    "对偶问题：  \n",
    "$\\qquad\\quad  \\underset{\\lambda}{max}\\;\\;\\theta(\\lambda) =\\;\\underset{\\lambda}{max}\\;\\;\\underset{w \\in R^d\\; b\\in R}{inf }L(w,b,\\lambda) $  \n",
    "\n",
    "$\\quad\\quad\\qquad  s.t. \\lambda_i\\geq 0 \\quad i=1,2，\\cdots$     \n",
    "  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$\\qquad\\quad  \\underset{\\lambda}{max}\\;\\;\\theta(\\lambda) =\\;\\underset{\\lambda}{max}\\;\\;\\underset{w \\in R^d\\; b\\in R}{inf }[\\;{||W||}^2+\\sum_{i=1}^n\\lambda_i (1- y_i(w^Tx_i+b))] $  \n",
    "\n",
    "$\\quad\\quad\\qquad  s.t. \\lambda_i\\geq 0 \\quad i=1,2，\\cdots$    \n",
    "  \n",
    "<br>\n",
    "<br>\n",
    "求出下确界：  \n",
    "\n",
    "$\\qquad\\quad\\frac{\\partial L(w，b,\\lambda)}{\\partial w}=0 \\quad \\Rightarrow  w-\\sum_{i=1}^n \\lambda_i y_i x_i =0$  \n",
    "\n",
    " $\\qquad\\quad \\frac {\\partial L(w，b,\\lambda)}{\\partial b}=0 \\quad \\Rightarrow  \\sum_{i=1}^n \\lambda_i y_i =0$  \n",
    " 代入L  \n",
    " \n",
    " \n",
    "$\\qquad\\quad  \\underset{\\lambda}{max}\\;\\;\\theta(\\lambda) =\\;\\underset{\\lambda}{max}\\;\\; \\sum_{i=1}^n\\sum_{j=1}^n\\lambda_i\\lambda_jy_iy_jx_i^tx_j \\;-\\;\\sum_{i=1}^n\\lambda_i$\n",
    "\n",
    "$\\quad\\quad\\qquad  s.t. \\lambda_i\\geq 0 \\quad i=1,2，\\cdots$  \n",
    "  \n",
    "$\\quad\\quad\\quad\\qquad   \\sum_{i=1}^n \\lambda_i y_i =0 \\quad i=1,2，\\cdots$    \n",
    "  \n",
    "    \n",
    "<br>\n",
    "\n",
    "### 分析决策面和支持向量\n",
    "决策面方程：  \n",
    "\n",
    " $\\quad\\quad\\qquad  w=\\sum_{i=1}^n \\lambda_i y_i x_i $  \n",
    "   \n",
    " $\\quad\\quad\\qquad y=w^Tx+b\\;=\\;   \\sum_{i=1}^n \\lambda_i y_i x_i^Tx_i \\;\\;+\\;\\;b$  \n",
    " \n",
    "<br>  \n",
    "    \n",
    " 在求决策面方程的过程中确保了：  \n",
    "  $\\quad\\quad\\qquad 1.每个样本都正确分类： y_i(w^Tx_i+b)-1 \\geq 0$  \n",
    "  $\\quad\\quad\\qquad 2.\\quad\\lambda_i \\geq 0$  \n",
    "  $\\quad\\quad\\qquad 3.\\quad\\lambda_i [\\lambda_i(y_i(w^Tx_i+b)-1)] =0$  \n",
    "    \n",
    "      \n",
    "<br>\n",
    "\n",
    "所以对计算$w$来分析：  \n",
    "$\\qquad \\qquad \\quad\n",
    "        \\left.\n",
    "        \\begin{array}{l}\n",
    "         y_i(w^Tx_i+b)-1 >0\\;&\\;则 \\quad \\lambda_i=0  \\quad 计算w=\\sum_{i=1}^n \\lambda_i y_i x_i \\;时这个样本不参加计算\\\\\n",
    "          \\lambda_i>0 \\;&\\;则 \\quad y_i(w^Tx_i+b)-1 =0  \\quad 计算w=\\sum_{i=1}^n \\lambda_i y_i x_i 所有\\lambda_i>0样本参加计算\\\\\n",
    "        \\end{array}\n",
    "        \\right\\}\n",
    "          .\n",
    "$   \n",
    "  \n",
    "故所有满足$𝛼_𝑖>0$的样本必有$𝑦_𝑖  (𝒘^𝑇 𝒙_𝑖+𝑏)=1$，这样的样本称为支持向量，它们确定了决策面的位置.\n",
    "  \n",
    " <img src=\"../../img/Pattern_recognition/linear-spe-svm/guocheng2.PNG\" />  \n",
    "   \n",
    "     \n",
    " ###### 如何求b\n",
    " 支持向量代入：  \n",
    " $\\quad\\quad 𝑦_𝑖  (𝒘^𝑇 𝒙_𝑖+𝑏)=1 \\Rightarrow b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实列求求线性支持向量机的决策面方程\n",
    "#x1 =(0, 0),  y1 = +1\n",
    "#x2 =(1, 0),  y2 = +1\n",
    "#x3 =(2, 0),  y3 = -1\n",
    "#x4 =(0, 2),  y4 = -1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
