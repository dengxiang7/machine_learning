{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  训练误差  \n",
    "在训练集上的误差  \n",
    "  \n",
    "### 泛化误差  \n",
    "在测试集上的误差  \n",
    "  \n",
    "### 欠拟合  \n",
    "在训练集上的误差过大，无法得到准确预测（学不到共有的特征，预测率低）。  \n",
    "  \n",
    "### 过拟合  \n",
    "在训练集上的误差远远低于测试集上的误差。（学的一些独有的特征导致在预测别的样本时无法准确预测）  \n",
    "  \n",
    "    \n",
    " 解决方法：  \n",
    " $\\qquad\\qquad\\quad$1、增大训练集可以缓解过拟合线性（但是获得大训练集高价可能较高）  \n",
    "   \n",
    "   \n",
    "  $\\qquad\\qquad\\quad$2、减缓过拟合常用方法：权重衰减法  \n",
    "  \n",
    "    \n",
    "  $\\qquad\\qquad\\quad$3、减缓过拟合常用方法：丢弃法 \n",
    "    \n",
    "### 权重衰减     \n",
    "    \n",
    " \n",
    "   \n",
    "  1、$L_2$范数正则化  \n",
    "    \n",
    "   $\\qquad$ 在模型的损失函数上，增加权重参数的$L_2$范数，并为权重范数配上一个惩罚系数。  \n",
    "     \n",
    "       \n",
    "   $\\qquad$损失函数：$l_1(w_1,w_2,\\cdots,w_n,b)=\\frac{1}{n}\\sum_{i=1}^n(x_1w_1 +x_2w_2+\\cdots+x_nw_n+b -y)^2$  \n",
    "     \n",
    "   $\\qquad$权重正则化加惩罚系数：$\\frac{\\lambda}{2n}||w|||^2$  \n",
    "     \n",
    "   $\\qquad$重写损失函数：$l_2(w_1,w_2,\\cdots,w_n,b)=l_1(w_1,w_2,\\cdots,w_n,b)+\\frac{\\lambda}{2n}||w|||^2$   \n",
    "     \n",
    "   $\\qquad$损失函数对$w,b$求导：$\\;\\;\\frac{\\partial l_2}{\\partial w}=\\frac{\\partial l_1}{\\partial w}+\\frac{\\lambda}{n}w$  \n",
    "     \n",
    "   $\\qquad\\qquad\\qquad\\qquad\\quad\\quad \\frac{\\partial l_2}{\\partial b}=\\frac{\\partial l_1}{\\partial b}$  \n",
    "       \n",
    "   $\\qquad\\qquad$从这个式子可以看出最优值时$\\lambda$ 越大时w越小，变量维对应的权重越小  \n",
    "     \n",
    "       \n",
    "   $\\qquad$此时梯度下降法更新的参数：$w=w-\\eta(\\frac{\\partial l_1}{\\partial w}+\\frac{\\lambda}{n}w)\\;\\Rightarrow\\;w=(1-\\frac{\\eta\\lambda}{n})w-\\eta\\frac{\\partial l_1}{\\partial w}$    \n",
    "     \n",
    "     \n",
    "   $\\qquad\\qquad$从这个式子可以看出最优值时$\\eta\\geq 0 \\;\\;\\;\\;\\lambda \\geq0 \\;\\;\\;\\;n>0 \\;\\;\\;\\;(1-\\frac{\\eta\\lambda}{n}) \\leq 1$ 所以每次更新$w$时w变得比原本小，这也是权重衰减  \n",
    "     \n",
    "       \n",
    "   <br>  \n",
    "   \n",
    "   $\\qquad L_2$范数正则化:的目的是在求得损失函数最小的同时，也保证拟合函数的波动是最小的；（奥卡姆剃刀原则）波动小则对数据的拟合更好。\n",
    "       \n",
    "   <br>\n",
    "   \n",
    "  2、为什么$L_2$范数正则化可以防止过拟合  \n",
    "    \n",
    "    \n",
    "   $\\qquad$首先 正则为可以让权重参数的总值变小，那么可能有更多$w_i$为0,拟合函数的波动更小，波动小则对数据的拟合更好。  \n",
    "     \n",
    "   $\\qquad$其次在过拟合时，拟合函数往往要顾虑到每一个点所以系数往往很大，波动程度更大，而正则化则约束参数的范数，控制参数的范围。使波动变小 \n",
    "     \n",
    "   \n",
    "   ![](../../img/Pattern_recognition/base/wd1.PNG)\n",
    "        \n",
    "\n",
    "<br>  \n",
    "  \n",
    "    \n",
    "###  丢弃法  \n",
    "  \n",
    "  对隐藏层使用丢弃法时，隐藏层单元有一定概率会被丢弃；设丢弃概率为P,则该隐层单元有p概率会被丢弃。丢弃概率p是超参数。  \n",
    "    \n",
    "    \n",
    "    \n",
    " 丢弃法的目的：同权重衰减法一样目的是是某些节点的权重为0，只是手法略有不同；但都是使预测函数不过分依赖某些点而导致过拟合。\n",
    "  ![](../../img/Pattern_recognition/base/dropout1.PNG)  \n",
    "    \n",
    "      \n",
    "     \n",
    "<br>\n",
    "  \n",
    "### 正向传播\n",
    "正向传播：计算损失；反向传播：更新参数；  \n",
    "  \n",
    "正向传播：对神经网络，沿着输入层到输出层逐层计算，并存储中间变量。  \n",
    "  \n",
    "例如单隐层：输入$x \\in R^d $ 中间层$z=w^{(1)x} 进激活函数 \\quad h=\\phi(z) $ 输出层 $0=w^2h \\quad$权重正则化：$s=\\frac{\\lambda}{2}(||w^{(1)}||_F^2+||w^{(2)}||_F^2)$\n",
    "  \n",
    "  ![](../../img/Pattern_recognition/base/forward.PNG)\n",
    "  \n",
    "<br>    \n",
    "      \n",
    "### 反向传播  \n",
    "正向传播：计算损失；反向传播：更新参数；  \n",
    "  \n",
    "反向传播：参见BP算法    \n",
    "  \n",
    "    \n",
    "      \n",
    " <br>  \n",
    "   \n",
    "### 数值稳定性   \n",
    "1、衰减  \n",
    "  \n",
    "$\\qquad\\;\\;$当神经网络的层次较多时，数值的稳定性就会变差；例如一个30层网络当权重小于1时（假如都为0.2，一一映射）输出为X与$0.2^30$；（衰减）  \n",
    "  \n",
    "2、爆炸：  \n",
    "$\\qquad\\;\\;$例如一个30层网络当权重大于1时（假如都为5，一一映射）输出为X与$5^30$；（爆炸）  \n",
    "  \n",
    " <br>     \n",
    "      \n",
    "3、解决方法    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
