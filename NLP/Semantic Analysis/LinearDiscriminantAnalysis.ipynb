{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2bdc61",
   "metadata": {},
   "source": [
    "# 线性判别分析（linear Discriminant Analysis， LDA）  \n",
    "&emsp;&emsp;  LDA（最早有Fisher提出，所i也称作Fisher判别）是一个二值判别方法，是一种有监督算法。因此需要对文本文档的类别进行标注。  \n",
    "  \n",
    "&emsp;&emsp; LDA的思想：给定训练样本集，设法将样本投影到一条直线上，使得同类样本的投影点尽可能接近、异类样本点的投影尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，在根据投影点的位置来判别新样本的类别。   \n",
    "\n",
    "&emsp;&emsp; LDA的做法：给定数据集$D=\\{(x_i,y_i)\\}_{i=1}^m$,令$X_i,\\mu_i,\\Sigma_i $分别表示第$i$类$i\\in \\{0,1\\}$样本集合、集合的均值向量、集合的协方差矩阵。  \n",
    "   \n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp; 投影点到中心的距离为(向量的点积转向量运算)：$d_0 = |\\mu_0|cos\\theta = |\\mu_0|\\frac{\\mu_0 \\cdot w }{|\\mu_0||w|} = w^T \\mu_0$&emsp;和&emsp;$d_1  = w^T \\mu_1$   \n",
    "\n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp; 投影后两类样本的协方差：$w^T\\Sigma_0 w$、$w^T\\Sigma_1 w$  &emsp;&emsp;(定理：数据去中心化后， $\\frac{1}{n}X  X^T$  等于协方差矩阵)(所以：投影后的协方差矩阵为：$\\frac{1}{n}(w^TX)  (w^TX)^T = w^T\\frac{1}{n} XX^Tw = w^T\\Sigma w$)\n",
    "  \n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp; 同类样本协方差尽可能小：$w^T\\Sigma_0 w +w^T\\Sigma_1 w $   \n",
    "  \n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp; 不同类样本中心尽可能远：$||w^T\\mu_0  - w^T\\mu_1||_2^2  $    \n",
    "  \n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp; 同时考虑二者可得最大化的目标函数：$J=\\frac{||w^T\\mu_0  - w^T\\mu_1||_2^2 }{w^T\\Sigma_0 w +w^T\\Sigma_1 w} = \\frac{w^T(\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^Tw}{w^T(\\Sigma_0+\\Sigma_1)w}$  \n",
    "  \n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp;令：$S_w = \\Sigma_0 + \\Sigma_1$  &emsp;&emsp; $S_b = (\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^T$ &emsp;&emsp;则：$J =  \\frac{w^TS_bw }{w^TS_w w}$  \n",
    "\n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp;拉格朗日求解得：令 $w^TS_w = 1 $&emsp;则&emsp;$\\underset{w}{min} \\quad - w^TS_b w \\quad s.t.\\quad w^TS_w w = 1   \\qquad \\iff S_bw = \\lambda S_w w$  \n",
    "  \n",
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp;注意：$S_bw = (\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^T w $ &emsp; ($(\\mu_0-\\mu_1)^T w $是标量)则$S_bw$与$(\\mu_0-\\mu_1)$同方向。则可以令：$S_bw = \\lambda(\\mu_0-\\mu_1)$带入上式可以得到$w$的解。  \n",
    "  \n",
    " &emsp;&emsp; &emsp;&emsp; &emsp;&emsp;解：$w = S_w^{-1}(\\mu_0 - \\mu_1)$ \n",
    "\n",
    "对上述目标函数求解$w$，即为LDA算法。  \n",
    "  \n",
    "### LDA 在语义分析中的应用  \n",
    " &emsp;&emsp;LDA是最简单的语义分析技术，训练LDA模型只需要计算两类样本的质心（平均位置）。用两个质心向量得到分类线。用点积将每个TF-IDF向量投影到质心之间的连线上（计算得分）。  \n",
    "   \n",
    "  &emsp;&emsp; $\\color{#F00}{ LDA 在语义分析上的作用就是对文档进行两个语义上的分类。} $ \n",
    "\n",
    "#### 协方差矩阵\n",
    "&emsp;&emsp; 协方差：表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。从直观上来看，协方差表示的是两个变量总体误差的期望。  \n",
    "&emsp;&emsp; $cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY]-E[X]E[Y]$  \n",
    "\n",
    "&emsp;&emsp; 协方差矩阵：是从标量随机变量到高维度随机向量的自然推广。例如二维随机变量$(X_1,X_2)$,则协方差矩阵(二维向量的协方差矩阵，$X_1$是第一维度，$E[X_1]$是所有样本第一维度的期望，同理得第二维度)为：  \n",
    "&emsp;&emsp; $ cov=\\begin{pmatrix} c_{11} &  c_{12} \\\\  c_{21} &  c_{22} \\\\ \\end{pmatrix} $  \n",
    "\n",
    "&emsp;&emsp; $ c_{11}=(E[X_1-E[X_1]]^2) $  \n",
    "  \n",
    "&emsp;&emsp; $ c_{12}=(E[X_1-E[X_1]]E[X_2-E[X_2]]) $  \n",
    "  \n",
    "&emsp;&emsp; $ c_{21}=(E[X_2-E[X_2]]E[X_1-E[X_1]]) $  \n",
    "  \n",
    "&emsp;&emsp; $ c_{22}=(E[X_2-E[X_2]]^2) $  \n",
    "  \n",
    "   \n",
    "#### 正交投影\n",
    "&emsp;&emsp; 向量投影：设两个非零向量a与b的夹角为$\\theta$，则将$|b|·cos\\theta$ 叫做向量b在向量a方向上的投影或称标投影。$|b|cos\\theta = \\frac{a\\cdot b}{|a|}$  \n",
    "  \n",
    "&emsp;&emsp; 正交投影：指像空间U和零空间W相互正交子空间的投影。(投影是从向量空间映射到自身的一种线性变换,如：现实中阳光将事物投影到地面上一样，投影变换将整个向量空间映射到它的其中一个子空间，并且在这个子空间中是恒等变换。)    \n",
    "  \n",
    "  \n",
    "&emsp;&emsp; $P^2 = P$投影的严格定义是：一个从向量空间$V$射到它自身的线性变换$P$是投影，当且仅当。另外一个定义则较为直观：$P$是投影，当且仅当存在$V$的一个子空间$W$，使得$P$将所有$V$中的元素都映射到$W$中，而且$P$在$W$上是恒等变换。用数学的语言描述，就是：  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\exists W$使得 $\\forall u\\in V , P(u) \\in W \\text{并且对} \\forall u\\in W, P(u) = u $  \n",
    "  \n",
    "&emsp;&emsp; 举例：在现实生活中，阳光在地面上留下各种影子。这就是投影变换最直白的例子。可以理想化地假设阳光都是沿着同一个方向（比如说垂直于地面的角度）照射而来，大地是严格的平面，那么，对于任意一个物体（比如说一只正在飞行的鸟），它的位置可以用向量(x,y,z)来表示，而这只鸟在阳光下对应着一个影子，也就是(x,y,0)。这样的一个变换就是一个投影变换。它将三维空间中的向量(x,y,z)到映射到向量(x,y,0)。这是在x-y平面上的投影。这个变换可以用矩阵表示为   \n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  $ P=\\begin{bmatrix}1 &  0 & 0 \\\\  0 & 1 & 0 \\\\  0 & 0 & 0 \\\\ \\end{bmatrix} $   \n",
    "  \n",
    "因为对任意一个向量(x,y,z)，这个矩阵的作用是：  \n",
    "  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  $ P\\begin{pmatrix} x \\\\  y  \\\\  z \\\\ \\end{pmatrix}  = \\begin{pmatrix} x \\\\  y  \\\\  0 \\\\ \\end{pmatrix}$    \n",
    "\n",
    "注意到如果一个向量原来就是表示地面上的一点的话（也就是说它的z分量等于0），那么经过变换P后不会有改变。也就是说这个变换在子空间x-y平面上是恒等变换，这证明了P的确是一个投影。另外，  \n",
    "  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  $ P^2\\begin{pmatrix} x \\\\  y  \\\\  z \\\\ \\end{pmatrix}= P\\begin{pmatrix} x \\\\  y  \\\\  0 \\\\ \\end{pmatrix}  = \\begin{pmatrix} x \\\\  y  \\\\  0 \\\\ \\end{pmatrix}$   \n",
    "\n",
    "所以P=P2，这也证明P的确是投影。    \n",
    "  \n",
    " &emsp;&emsp; 正交投影：如果向量空间被赋予了内积，那么就可以定义正交和其它相关的概念(比如线性算子的自伴随性)了。在内积空间（赋予了内积的向量空间）中，有正交投影的概念。具体来说，正交投影是指像空间$U$和零空间$W$相互正交子空间的投影。也就是说，任意 $u \\in U$，$w \\in W$ ，它们的内积$u\\cdot w $ 都等于0。一个投影是正交投影，当且仅当它是自伴随的变换，这意味着正交投影的矩阵(变换矩阵P)有特殊的性质。如果投影是在实向量空间中，那么它对应的矩阵是对称矩阵：$P= P^T$ 。那么   \n",
    "   \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  $ \\forall u \\in U, w \\in W$有$u\\cdot  w =P(U)\\cdot w $  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76f35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e595ed0e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;  \n",
    "&emsp;&emsp;  \n",
    "&emsp;&emsp;  \n",
    "&emsp;&emsp;  \n",
    "\n",
    "\n",
    "\n",
    "正交投影：https://zhuanlan.zhihu.com/p/330652546\n",
    "![](img/proj.jpeg) \n",
    "\n",
    "\n",
    "&emsp;&emsp;  \n",
    "&emsp;&emsp;  \n",
    "&emsp;&emsp;  \n",
    "&emsp;&emsp; \n",
    "\n",
    "LDA 投影公式的计算：https://www.pianshen.com/article/99621414510/\n",
    "![](img/LAD_PRoJ.jpeg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f646255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
