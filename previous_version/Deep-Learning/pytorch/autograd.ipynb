{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch怎么实现对函数求导    \n",
    "  \n",
    "神经网络是非常大的复合函数，对于这个大型的复合函数求微分都不擅长。    \n",
    "    \n",
    "  \n",
    "pytorch 的求导从来都不是显示计算整个网络的复合函数的表达式。  \n",
    "  \n",
    "事实上，通过显示求解数学方程式来计算这样大的复合函数的梯度是不现实的。特别是这些曲线存在于大量的维数中。  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "#### pytorch求导基础  \n",
    "  \n",
    "张量：存在数据的对象。一个n维数组。当某个张量对象设置.requires_grad=True 之后。他们开始形成一个反向图，跟踪应用于他们的每个操作，使用所谓的同台计算图（DCG）计算梯度。  \n",
    "  \n",
    "创建启用梯度的张量的方法：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np  \n",
    "\n",
    "# 方法一：  \n",
    "x=torch.tensor(data, dtype=None, device=None, requires_grad=False)  #此时x就是启用了梯度的张量  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "Autograd对象：这个类是一个计算导数的引擎。它记录了梯度张量上所有操作的一个图，并创建了一个称为动态计算图的非循环图。这个图的叶子节点是输入张量，根节点是输出张量。 梯度是通过跟踪从根到叶的图形，并使用链式法则将每个梯度相乘来计算。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
