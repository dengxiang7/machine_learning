{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 子空间聚类  \n",
    "  \n",
    "  线性空间，子空间 知识：查看（数学->线性代数->线性空间 ）的内容。  \n",
    "  \n",
    "  \n",
    "传统聚类算法根据思想可以划分为5类：1、划分法 2、层次法 3、密度法 4、网格法 5、模型法   \n",
    "   \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "## 子空间聚类\n",
    "    \n",
    "    \n",
    "高维数据聚类是聚类分析技术的难点和重点。子空间聚类是实现高维数据聚类的有效途径，它是在高维数据空间中对传统聚类算法的一种扩展，其思想是将搜索局部化在相关维中进行。  \n",
    "\n",
    "**子空间聚类的思想是将搜索局部化在相关维中进行**   \n",
    "  \n",
    "\n",
    "**为了解决传统聚类算法对高维数据空间进行聚类时会遇到的困难。（维度灾难，数据稀疏），R.Agrawal首次提出了子空间聚类的概念，以解决高维数据的聚类问题。**  \n",
    "  \n",
    "传统聚类方法在高维数据集中进行聚类时主要会遇到两个问题：   \n",
    "1、高维数据集存在大量无关属性使得在所有维中存在簇的可能性几乎为0  \n",
    "2、高维空间中数据分布稀疏，其中数据间距离几乎相等是普遍现象，而传统聚类是基于距离算法的，因此传统方法在高维空间无法构建聚类结构。  \n",
    "\n",
    "\n",
    "**解决方法：**  \n",
    "1、特征变换  \n",
    "  \n",
    "2、特征选择  \n",
    "  \n",
    "3、子空间聚类  \n",
    "    \n",
    "  \n",
    "一般情况下，特征是相关的，例如图像的R,G,B三个特征。那么如果简单的抛弃R值，也将一起失去G,B特征的信息。  \n",
    "* 特征变换：  \n",
    "    就是通过一定的数学运算，对原有的特征进行运算得到一组新特征。（以达到降维）。如把R,G,B通过运算合到一个新特征上。如：PCA->方差 如LDA->均值    \n",
    "    \n",
    "  \n",
    "* 特征选择  \n",
    "    而特征选择，是直接选择那些线性相关的特征进行聚类（如直接选择，线性相关的R，G，B三个特征）。不再是对对原有的特征进行运算得到一组新特征。  \n",
    "    特征选择只在那些相关的子空间上执行挖掘任务，因此它比特征转换更有效的减少维数，特征选择一般使用贪心策略等搜索方法搜索不同的特征子空间，然后使用一些标准来评价这些子空间，从而找到所需的簇。\n",
    "          \n",
    "          \n",
    "* 子空间聚类  \n",
    "  子空间聚类拓展了特征选择任务，它尝试在相同数据集的不同子空间上发现聚类。考虑到不同簇存在于不同子空间。  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "    \n",
    "<br>  \n",
    "\n",
    "## 子空间聚类  \n",
    "  \n",
    "  高维聚类的难度：  \n",
    "  1、高维使得原始数据的可视化和理解输入变得困难   \n",
    "  2、高维空间中数据稀疏   \n",
    "  3、随着维数的增加，所有子空间的完整枚举变得难以处理  \n",
    "  4、大多数底层聚类技术依赖于结果和降维技术的选择  \n",
    "  5、许多维度可能是不相关的，并且可以在有噪声的数据中屏蔽现有的聚类  \n",
    "  6、一种常见方法是特征选择（选择相关的特征进行聚类），但是在某些情况下，识别冗余维度并不容易。  \n",
    "       \n",
    "\n",
    "什么是子空间聚类？   \n",
    "  子空间聚类是一种在不同子空间（一个或多个维度的选择）中发现聚类的技术。基本假设是：我们可以找到只有维度子集定义的有效聚类（不需要具有所有N个特征的一致性。）子空间聚类是传统N维聚类分析的扩展，它允许通过创建行和列聚类同时对特征和观测进行分组。  \n",
    "    在特征和观察的空间中，产生的聚类可能重叠。  \n",
    "    \n",
    "\n",
    "子空间聚类的类型  \n",
    "  基于搜索策略，我们可以区分两种类型的子空间，  \n",
    "  1、自下而上的方法首先在低维（1D）空间中找到聚类并迭代合并他们以处理更高维空间  \n",
    "  2、自上而下的方法在整个维度集中查找聚类并评估每个聚类的子空间  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "   \n",
    "\n",
    "# 子空间聚类（总结,综述）（重要）    \n",
    "\n",
    "* 高维空间聚类的难度。  \n",
    "  1、高维数据集存在大量无关属性使得在所有维中存在簇的可能性几乎为0   \n",
    "  2、高维空间中数据分布稀疏，其中数据间距离几乎相等是普遍现象，而传统聚类是基于距离算法的，因此传统方法在高维空间无法构建聚类结构。  \n",
    "  3、许多维度可能是不相关的，并且可以在有噪声的数据中屏蔽现有的聚类 \n",
    "  4、高维使得原始数据的可视化和理解输入变得困难    \n",
    "  5、随着维数的增加，所有子空间的完整枚举变得难以处理  \n",
    "  6、大多数底层聚类技术依赖于结果和降维技术的选择   \n",
    "  7、一种常见方法是特征选择（选择相关的特征进行聚类），但是在某些情况下，识别冗余维度并不容易。 \n",
    "  \n",
    "<br>  \n",
    "\n",
    "* 解决方法。    \n",
    "一般情况下，特征是相关的，例如图像的R,G,B三个特征。那么如果简单的抛弃R值，也将一起失去G,B特征的信息。  \n",
    "1、**特征变换**：  \n",
    "就是通过一定的数学运算，对原有的特征进行运算得到一组新特征。（以达到降维）。如把R,G,B通过运算合到一个新特征上。如：PCA->方差 如LDA->均值  \n",
    "2、**特征选择**  \n",
    "而特征选择，是直接选择那些线性相关的特征进行聚类（如直接选择，线性相关的R，G，B三个特征）。不再是对对原有的特征进行运算得到一组新特征。  特征选择只在那些相关的子空间上执行挖掘任务，因此它比特征转换更有效的减少维数，特征选择一般使用贪心策略等搜索方法搜索不同的特征子空间，然后使用一些标准来评价这些子空间，从而找到所需的簇。  \n",
    "3、**子空间聚类**   \n",
    "**子空间聚类是对特征选择的一种扩展。即聚类时：不同类别选择不同的组合属性去完成聚类。（即在不同的子空间中聚类不同的类别。）（其思想来源是：不同类别，可能由不同的组合属性来决定。而那些冗余的属性又会破坏原本类别的聚类结构）**\n",
    "  \n",
    "<br>  \n",
    "\n",
    "* 子空间聚类的定义  \n",
    "    同数据集的不同子空间上发现聚类。考虑到不同簇存在于不同子空间。子空间聚类是一种在不同子空间（一个或多个维度的选择）中发现聚类的技术。  \n",
    "      \n",
    "    **全属性维度：对一些类别来说可能存在某些冗余的属性，而这些冗余的属性，会对这些类别的聚类结构造成很大的影响，导致聚类不成功。**  \n",
    "      \n",
    "    **子空间聚类的思想：类别A可能在某些属性是线性相关的（也就是这些属性决定了类别A）,类别B可能在另一些属性上是线性相关的（即另一些属性决定了类别B）。我们聚类时：对不同类别使用不同组合属性去聚类。**\n",
    "    \n",
    "    \n",
    "<br>  \n",
    "\n",
    "### **总结一下什么是子空间聚类**  \n",
    "  \n",
    "  1、不同的类别可能由不同线性相关的属性决定（线性相关的属性是一个子空间）  \n",
    "  2、对类别而言增加冗余的属性会破坏这个类别的结构  \n",
    "  由上面这两个点可以得到子空间聚类的定义：即聚类时：不同类别选择自身类别的线性相关属性去完成聚类。（不增加这个类别的冗余属性）。  \n",
    "  即子空间聚类是一种在不同子空间（一个或多个维度的选择）中发现聚类的技术。  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "举例：  \n",
    "全属性样本$X(x_1,x_2,x_3,x_4,x_5,x_6)$,有6个属性。这个训练集样本总分为3类(A,B,C) ，A类由线性相关的属性$x_1,x_3,x_4$决定，B类由线性相关的属性$x_1,x_2,x_4,x_6$决定。C类由属性$x_5$决定。这时如果对B类增加一个冗余属性$x_3$可能会对B的聚类结构造成很大的破坏。这时的子空间聚类，即在不同子空间中发现聚类结构，也就是聚类时进行特征选择，在不同的特征组合中进行聚类，例如在$x_1,x_3,x_4$子空间中聚类A,在$x_1,x_2,x_4,x_6$子空间中聚类B,在$x_5$属性中聚类C。   \n",
    "\n",
    "<br>\n",
    " \n",
    "某些类样本：只在自己的子空间中，不在其他类别的子空间中。（例如A类在$x_1,x_3,x_4$子空间中，不在$x_1,x_2,x_4,x_6$子空间中，当A类样本的全属性，选择B类的子空间，时在B的子空间中这个A的样本是没有意义的，是一个噪声。）\n",
    "  \n",
    "<br>  \n",
    "  \n",
    "self-expression性质：  \n",
    "    子空间中的一点，可以由同一子空间中其他点来线性表示。 X=XC \n",
    "\n",
    "  \n",
    "<br>    \n",
    "\n",
    "使用self-expression性质的子空间聚类： X=XC  \n",
    "\n",
    "  $\n",
    "        \\begin{pmatrix}\n",
    "        x_1^1 & x_1^2 &  \\cdots & x_1^n \\\\\n",
    "        \\vdots  & \\vdots & \\ddots & \\vdots \\\\\n",
    "        x_n^1 &  x_n^2 & \\cdots &  x_n^n \\\\\n",
    "        \\end{pmatrix}     \n",
    "$  =     $\n",
    "        \\begin{pmatrix}\n",
    "        x_1^1 & x_1^2 &  \\cdots & x_1^n \\\\\n",
    "        \\vdots  & \\vdots & \\ddots & \\vdots \\\\\n",
    "        x_n^1 &  x_n^2 & \\cdots &  x_n^n \\\\\n",
    "        \\end{pmatrix}     \n",
    "$ $\\times$  $\n",
    "        \\begin{pmatrix}\n",
    "        c_1^1 & c_1^2 &  \\cdots & c_1^n \\\\\n",
    "        \\vdots  & \\vdots & \\ddots & \\vdots \\\\\n",
    "        c_n^1 &  c_n^2 & \\cdots &  c_n^n \\\\\n",
    "        \\end{pmatrix}     \n",
    "$    \n",
    "  \n",
    "从这个式子，可以看出，C的每一列就相当于某个类别的子空间。我们只取C的一列来做计算。用来观测子空间聚类的过程。  \n",
    "  \n",
    "$\n",
    "        \\begin{pmatrix}\n",
    "        x_1^1*c_1^1 +x_1^2*c_2^1 +……+ x_1^n*c_n^1 &  \\cdots  \\\\  \n",
    "        x_2^1*c_1^1 +x_2^2*c_2^1 +……+ x_2^n*c_n^1 &  \\cdots  \\\\\n",
    "        \\vdots  & \\vdots \\\\\n",
    "       x_n^1*c_1^1 +x_n^2*c_2^1 +……+ x_n^n*c_n^1 &  \\cdots \\\\\n",
    "        \\end{pmatrix}     \n",
    "$    \n",
    "  \n",
    "\n",
    "  \n",
    "**这里C提供了两种角度来观测子空间聚类  \n",
    "1、 样本角度： C的列可以从样本的角度观察到样本之间是否是线性相关的。（同一子空间中样本是线性相关的。）样本线性相关  \n",
    "2、属性角度（不同子空间角度）：X=XC之后新的X的每一列的样本，都是独属于这个样本的可能子空间。（这一列的某些维度为0）（也就是样本属于类的特定于这个样本的子空间）**  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "# 子空间聚类（总结2.0版）  \n",
    "\n",
    "\n",
    "* 高维空间聚类的难度。  \n",
    "  1、高维数据集存在大量无关属性使得在所有维中存在簇的可能性几乎为0   \n",
    "  2、高维空间中数据分布稀疏，其中数据间距离几乎相等是普遍现象，而传统聚类是基于距离算法的，因此传统方法在高维空间无法构建聚类结构。  \n",
    "  3、许多维度可能是不相关的，并且可以在有噪声的数据中屏蔽现有的聚类 \n",
    "  4、高维使得原始数据的可视化和理解输入变得困难    \n",
    "  5、随着维数的增加，所有子空间的完整枚举变得难以处理  \n",
    "  6、大多数底层聚类技术依赖于结果和降维技术的选择   \n",
    "  7、一种常见方法是特征选择（选择相关的特征进行聚类），但是在某些情况下，识别冗余维度并不容易。 \n",
    "  \n",
    "<br>  \n",
    "\n",
    "* 解决方法。    \n",
    "一般情况下，特征是相关的，例如图像的R,G,B三个特征。那么如果简单的抛弃R值，也将一起失去G,B特征的信息。  \n",
    "1、**特征变换**：  \n",
    "就是通过一定的数学运算，对原有的特征进行运算得到一组新特征。（以达到降维）。如把R,G,B通过运算合到一个新特征上。如：PCA->方差 如LDA->均值  \n",
    "2、**特征选择**  \n",
    "而特征选择，是直接选择那些线性相关的特征进行聚类（如直接选择，线性相关的R，G，B三个特征）。不再是对对原有的特征进行运算得到一组新特征。  特征选择只在那些相关的子空间上执行挖掘任务，因此它比特征转换更有效的减少维数，特征选择一般使用贪心策略等搜索方法搜索不同的特征子空间，然后使用一些标准来评价这些子空间，从而找到所需的簇。  \n",
    "3、**子空间聚类**   \n",
    "**子空间聚类是对特征选择的一种扩展。即聚类时：不同类别选择不同的组合属性去完成聚类。（即在不同的子空间中聚类不同的类别。）（其思想来源是：不同类别，可能由不同的组合属性来决定。而那些冗余的属性又会破坏原本类别的聚类结构）**\n",
    "  \n",
    "<br>   \n",
    "\n",
    "* 举例：  \n",
    "全属性样本$X(x_1,x_2,x_3,x_4,x_5,x_6)$,有6个属性。这个训练集样本总分为3类(A,B,C) ，A类由线性相关的属性$x_1,x_3,x_4$决定，B类由线性相关的属性$x_1,x_2,x_4,x_6$决定。C类由属性$x_5$决定。这时如果对B类增加一个冗余属性$x_3$可能会对B的聚类结构造成很大的破坏。这时的子空间聚类，即在不同子空间中发现聚类结构，也就是聚类时进行特征选择，在不同的特征组合中进行聚类，例如在$x_1,x_3,x_4$子空间中聚类A,在$x_1,x_2,x_4,x_6$子空间中聚类B,在$x_5$属性中聚类C。   \n",
    "\n",
    "<br>\n",
    "\n",
    "* **子空间聚类的局限性！**  \n",
    "  \n",
    "  由于实际数据不一定符合线性子空间模型，所以其实际应用很受限，例如，在人脸图像聚类中，实际的人脸图像通常是不对齐的，并且常常包含对象的姿势和表情的变化。  \n",
    "    \n",
    "  **理解：什么是实际数据不一定符合线性子空间模型？例如：即使同一个类别的样本也可能在不同的子空间中。（A的子空间$x_1,x_3$但也有可能有A的样本，不存在于这个子空间，导致这个想象的原因是：目标位置的变化，图像通常是不对齐的，目标的形态改变等）**     \n",
    "    \n",
    "  这些就是实际数据不一定符合线性模型。同一类的样本不在同一个线性子空间中。  \n",
    "    \n",
    "  子空间聚类不能处理同一类图片不位于同一子空间的情况。\n",
    "    \n",
    "<br>    \n",
    "\n",
    "  \n",
    "<br>  \n",
    "* **子空间聚类的问题定义如下：**  \n",
    "**让$X\\in R^{D\\times N}$,D是全维度数，N是数据样本个数，X的每一列都是来自于n个子空间的并集，每个子空间是$R^D$的子集，$U_i^n\\{s_i\\}$。每个子空间的维度$d_i<<min\\{D,N\\} \\quad$ .(其实质就是对每列样本只取这列样本所属类别线性相关属性所在的维度。其他维度为0，N个样本都这样做，最后组成了X数据矩阵) 。 子空间聚类的目标就是把X的列分割为相应的子空间。**    \n",
    "   \n",
    "   \n",
    "<br>  \n",
    "  \n",
    "* 子空间聚类的局限性，加上，上述子空间聚类的定义，现有使用self-expression性质的子空间聚类。    \n",
    "   子空间的局限性：即使是同一类的样本，可能因为不对齐，存在一些动作变换，而导致这些同一类的样本也在不同的子空间中。  \n",
    "   self-expression性质：x=xc 学习特征向量，每个特征向量可能表示为其他特征向量的线性组合。每个样本学到的特征向量为XC。经过X=XC后，之后新的X每一列的样本，就是独属于这个样本的子空间。\n",
    "  \n",
    "<br>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
