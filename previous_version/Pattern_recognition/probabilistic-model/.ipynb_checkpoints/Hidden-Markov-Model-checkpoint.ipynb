{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率模型\n",
    "概率模型：提供一种描述框架，**将学习任务归结于计算变量的概率分布**(根据贝叶斯置信网得到样本的属性之间的关系依赖；对于一个新的样  \n",
    "$\\qquad\\quad\\quad$本可以计算样本属性的联合概率得到样本产生的概率。也可以根据属性之间的依赖关系推断变量的取值概率)  \n",
    "  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "推断：利用已知变量推测未知变量的概率分布。（参考贝叶斯网）  \n",
    "  \n",
    "<br>    \n",
    "  \n",
    "### 隐马尔可夫模型\n",
    "状态:$\\omega_i\\quad i=1,2,\\cdots$   \n",
    "\n",
    "t时刻状态：$\\omega（t）$  \n",
    "  \n",
    "长度t的离散时间上的状态序列：$\\omega^T=\\{\\omega（1）,\\omega（2）,\\cdots,\\omega（T）\\} \\qquad 如\\omega^4=\\{\\omega_1,\\omega_2,\\omega_1,\\omega_1\\}$   \n",
    "  \n",
    "状态转移概率矩阵：$ \\begin{pmatrix} a_{11} & a_{12}&a_{13} \\\\ a_{21} & a_{22}& a_{23}\\\\ a_{31} &a_{32}&a_{33} \\\\\\end{pmatrix} $  \n",
    "  \n",
    "转移图：  \n",
    "![](../../img/Pattern_recognition/proba_model/pro1.PNG)\n",
    "    \n",
    "\n",
    "\n",
    "隐马尔可夫模型是最简单的动态贝叶斯网。  \n",
    "  \n",
    " 隐变量：$\\omega^T=\\{\\omega(1),\\omega(2),\\cdots,\\omega(t)\\}\\quad \\omega(i) \\in \\Omega$ 表示t时刻的隐状态;$\\Omega$表示隐状态的取值空间 \n",
    "   \n",
    " 观测变量：$X=\\{x_1,x_2,\\cdots,x_t\\} \\quad x_i \\in \\chi \\quad$ 表示t时刻隐藏状态以一定概率发出的观测值；$\\chi=\\{v_i,v_2,\\cdots,v_k\\}$表示观测值的取值空间  \n",
    " $\\qquad\\qquad$有每个隐状态的发出概率满足$b_{ji}=P(x_j|\\omega_i) \\quad \\sum_{j=1}^kb_{ji}=1$  \n",
    "   \n",
    "状态图：  \n",
    "![](../../img/Pattern_recognition/proba_model/pro2.PNG)\n",
    " \n",
    "  \n",
    "马尔可夫链（时间序列上的观测图）：  \n",
    "![](../../img/Pattern_recognition/proba_model/pro3.PNG)  \n",
    "   \n",
    "     \n",
    " <br>    \n",
    "    \n",
    "样本产生的过程：  \n",
    "1、按照初始分布，产生一个初始隐状态  \n",
    "2、初始状态按照发射概率发射一个观测变量  \n",
    "3、初始隐状态按照概率转移矩阵进行状态转移，重复2，3   \n",
    "  \n",
    "<br>\n",
    "\n",
    "隐马尔可夫模型的类型：\n",
    "1、离散马尔可夫模型：观测量取值是离散随机向量  \n",
    "2、连续马尔可夫模型：观测量取值是连续随机向量  \n",
    "3、左右模型：状态从ID小到ID大，最后一个是吸收态。  \n",
    "4、各态历经模型：状态转移没有约束。  \n",
    "  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "隐马尔可夫模型的两个基本假设：  \n",
    "1、齐次性：t时刻的概率只与t-1时刻的状态有关，与t-1之间的状态无关，而且与时间t无关  \n",
    "2、观测序列条件独立性：每个隐状态的发射的观测值只与该时刻隐状态有关。$p(x_1,x_2,\\cdots,x_t|\\omega_1,\\omega_2,\\cdots,\\omega_t)=\\prod_{i=1}^tp(x_i|\\omega_i)$   \n",
    "  \n",
    "    \n",
    " <br>  \n",
    " \n",
    "隐马尔可夫模型的三个基本问题：  \n",
    "评估问题：给一个观测序列$X^T=\\{(x_1,x_2,\\cdots,x_t\\}$和一个模型$\\lambda=\\{\\pi,A,B\\}$ ；来对观测序列分类；或对下一个观测值做预测（推断）  \n",
    "  \n",
    "解码问题： 给一个观测序列$X^T=\\{(x_1,x_2,\\cdots,x_t\\}$和一个模型$\\lambda=\\{\\pi,A,B\\}$来确定观测序列的最佳隐状态序列$\\omega^T=\\{\\omega_1,\\omega_2,\\cdots,\\omega_t\\}$   \n",
    "  \n",
    "学习问题：给观测序列$X^T=\\{(x_1,x_2,\\cdots,x_t\\}$ 训练得出一个模型 $\\lambda=\\{\\pi,A,B\\}$，训练的目标是用这个模型$\\lambda$产生这个观测序列的概率最大$P(X|\\lambda)$   \n",
    "  \n",
    "   \n",
    "   \n",
    "<br>  \n",
    "<br>\n",
    "\n",
    "### 评估问题：  \n",
    "计算根据模型$\\lambda=\\{\\pi,A,B\\}$生成这个观测序列$X^T=\\{(x_1,x_2,\\cdots,x_t\\} \\quad $的概率 也就是计算$P(X^T|\\lambda)$ ；隐状态$\\omega_i \\in \\Omega$   \n",
    "  \n",
    "  <br>\n",
    "  \n",
    "*直接计算一个模型生成该观测序列的概率*：  \n",
    "\n",
    "$P(X^T|\\lambda)=\\underset{\\Omega}{\\sum}P(X^T|\\Omega,\\lambda)P(\\Omega|\\lambda)\\qquad$在该模型下生成该观测序列的概率=该模型下生成的所有可能的隐状态序列$\\times$隐状态下发出的对应观测值的概率；   \n",
    "  \n",
    "    \n",
    "$P(X^T|\\Omega,\\lambda)=p(x_1,x_2,\\cdots,x_t|\\omega_1,\\omega_2,\\cdots,\\omega_t,\\lambda)=\\prod_{i=1}^tp(x_i|\\omega_i,\\lambda)=\\prod_{i=1}^tb_{ii}\\quad$在该模型下某一个隐状态序列发出这个观测序列的概率，就是对应发射矩阵元素的乘积  \n",
    "  \n",
    "  <br>\n",
    "      \n",
    "$P(\\Omega|\\lambda)=\\pi_{\\omega_1}a_{\\omega_1\\omega_2}\\cdots a_{\\omega_{t-1}\\omega_t} \\quad$ 该模型生成某个隐状态序列的概率；也就是状态转移矩阵元素的乘积      \n",
    "  \n",
    " <br>  \n",
    " \n",
    " 所以根据一个模型生成该观测向量的概率为：  \n",
    " $P(X^T|\\lambda)=\\underset{\\Omega}{\\sum}P(X^T|\\Omega,\\lambda)P(\\Omega|\\lambda)=\\underset{\\Omega}{\\sum}\\prod_{i=1}^tb_{ii}(\\pi_{\\omega_1}a_{\\omega_1\\omega_2}\\cdots a_{\\omega_{t-1}\\omega_t})=\\underset{\\omega_1,\\omega_2,\\cdots,\\omega_t}{\\sum}\\pi_{\\omega_1}b_{1}a_{\\omega_1\\omega_2}\\cdots  a_{\\omega_{t-1}\\omega_t}b_{t}\\quad$  \n",
    "   \n",
    " 可以看出直接计算这个概率，就要计算所有可能得隐状态得序列。所以当隐状态过多时，计算过多（假如10各隐状态，15个时刻就要计算$10^{15}$次）。  \n",
    "   \n",
    "  <br>  \n",
    "  \n",
    " 为了解决这个问题，提出了前向和后向算法：  \n",
    "   \n",
    " * 前向算法：  \n",
    " (根据发射的独立性假设，每个时刻的计算只与上一个时刻计算有关)：  \n",
    " \n",
    " $\\alpha_{t}(i):$表示t时刻，状态$\\;i\\;$的观测序列为：$x_1,x_2,\\cdots,x_t$的概率  \n",
    "   \n",
    "   对于每一个时刻过往的观测序列概率为：$P(X^t|\\lambda)=\\sum_{j=1}^k\\alpha_{t}(j)$前进的方式对各个时刻求解  \n",
    "     \n",
    "   $\\alpha_{1}(i)=p(x_1,\\omega_1=i|\\lambda)$  \n",
    "     \n",
    "   $\\alpha_{t}(i)=p(x_1,x_2,\\cdots,x_t,\\omega_t=i|\\lambda)=\\sum_{j=1}^k p(x_1,x_2,\\cdots,x_t,\\omega_t=i,\\omega_{t-1}=j|\\lambda)$  \n",
    "     \n",
    "   $p(x_1,x_2,\\cdots,x_t,\\omega_t=i,\\omega_{t-1}=j|\\lambda)=p(x_1,x_2,\\cdots,x_t|\\omega_t=i,\\omega_{t-1}=j,\\lambda)p(\\omega_t=i,\\omega_{t-1}=j|\\lambda)$  \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=p(x_1,x_2,\\cdots,x_{t-1}|\\omega_{t-1}=j,\\lambda)p(x_t|\\omega_{t}=i,\\lambda)p(\\omega_t=i,\\omega_{t-1}=j|\\lambda)$(有状态发射的独立性可得)  \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=p(x_1,x_2,\\cdots,x_{t-1}|\\omega_{t-1}=j,\\lambda)p(x_t|\\omega_{t}=i,\\lambda)p(\\omega_t=i|\\omega_{t-1}=j，\\lambda)p(\\omega_{t-1}=j|\\lambda)$  \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=p(x_1,x_2,\\cdots,x_{t-1},\\omega_{t-1}=j|\\lambda)p(x_t|\\omega_{t}=i,\\lambda)p(\\omega_t=i|\\omega_{t-1}=j，\\lambda)$   \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\alpha_{t-1}(j)b_{x_t}(\\omega_t)a_{ji}$  \n",
    "     \n",
    "   $\\alpha_{t}(i)=\\sum_{j=1}^k\\alpha_{t-1}(j)b_{x_t}(\\omega_t)a_{ji}$(得到递推公式)  \n",
    "     \n",
    "   运算过程：  \n",
    "   ![](../../img/Pattern_recognition/proba_model/pro4.PNG)   \n",
    "     \n",
    "   对每一层也就是每一时刻计算$\\alpha_{t}(i)=\\sum_{j=1}^k\\alpha_{t-1}(j)b_{x_t}(\\omega_t)a_{ji}$；最后到了第T层，也就是T时刻就得到了所有隐状态的可能组合。  \n",
    "     \n",
    "   最总的概率$P(X^T|\\lambda)=\\sum_{j=1}^k\\alpha_{T}(j)$也就是对最后T时刻求和就可以了。  \n",
    "     \n",
    "   （假如10各隐状态，15个时刻就要计算$10*15$次）  \n",
    "     \n",
    "       \n",
    "<br>\n",
    "\n",
    "* 后向算法：\n",
    "和正向算法刚好相反从T到1：  \n",
    " $\\alpha_{t}(i)=\\sum_{j=1}^k\\alpha_{t+1}(j)b_{x_t}(\\omega_t)a_{ji}$   \n",
    "   \n",
    "<br>     \n",
    "       \n",
    "* 评估问题的应用：  \n",
    "1、分类问题：  \n",
    "$\\qquad\\qquad$为每一个类别建立一个HMM模型，用每个类别的观测样本可以训练出来一个模型$\\lambda=\\{\\pi,A,B\\}$参数；  \n",
    "$\\qquad\\qquad$在得到多个模型之后，对一个新样本进行分类时，进行贝叶斯决策  \n",
    "$ \\qquad\\qquad p(\\lambda_i|X)=\\frac{p(x|\\lambda_i)p(\\lambda_i)}{\\sum_{i=1}^cp(x|\\lambda_i)p(\\lambda_i)}$  \n",
    "$\\qquad\\qquad$所属类别是：后验概率最大的类别$p(\\lambda_i|X)\\quad$也等价于$\\underset{i}{argmax}(p(x|\\lambda_i)p(\\lambda_i))$,也就是某个类别的（先验概率$\\times$类条件概率） 的乘积最大。  \n",
    "$\\qquad\\qquad：p(x|\\lambda_i)$就是各个类别的类条件概率，也就是前向算法的结果；结果会很小；且各个类的类条件概率和不是等于1的，  \n",
    "![](../../img/Pattern_recognition/proba_model/pro6.PNG)   \n",
    "![](../../img/Pattern_recognition/proba_model/pro7.PNG)  \n",
    "  \n",
    " <br>  \n",
    " <br>\n",
    "  \n",
    "### 解码问题  \n",
    "给定一个观测序列$X^T=\\{x_1,x_2,\\cdots,x^t\\}$;和一个模型$\\lambda=\\{\\pi,A,B\\}$；用这个模型来确定这个观测序列的最优隐状态序列$\\omega=\\{\\omega_1,\\omega_2,\\cdots,\\omega_t\\}$ \n",
    "  \n",
    "* 解法一穷举法：  \n",
    "$\\omega^*=\\underset{\\omega_1,\\omega_2,\\cdots,\\omega_t}{arg\\;max}\\;\\;p(x_1,x_2,\\cdots,x^t|\\omega_1,\\omega_2,\\cdots,\\omega_t,\\lambda) \\qquad $也就是要找到所有可能的隐状态组合中，产生这个观测序列概率最大的哪个隐状态序列  \n",
    "  \n",
    "  该种方法解组合数太多，不适用。  \n",
    "    \n",
    "    \n",
    "    \n",
    "<br>  \n",
    "<br>\n",
    "      \n",
    "* 解法二 Viterbi算法：\n",
    " \n",
    " 也就是前向算法中；在每层（也就是每一个时刻t）时，只取出现该时刻观测值最大的状态；而不是取所有状态的和。\n",
    "    \n",
    "  定义：$\\delta_t(i)$为t时刻，状态i，时最优观测序列。  \n",
    "   \n",
    "    $\\delta_{1}(i)=p(x_1,\\omega_1=i|\\lambda)$  \n",
    "     \n",
    "   $\\delta_{t+1}(j)=\\underset{\\omega_1,\\omega_2，\\cdots，\\omega_t=i}{max}\\;\\;p(x_1,x_2,\\cdots,x_t,x_{t+1},\\omega_1,\\omega_2，\\cdots，\\omega_t=i,\\omega_{t+1}=j|\\lambda)\\quad$  \n",
    "   $\\qquad\\qquad$也就是从t时刻到t+1时刻转移时，选取t+1时刻出现对应观测值最大隐状态做为转移对象。  \n",
    "     \n",
    "   $p(x_1,\\cdots,x_t,x_{t+1},\\omega_1，\\cdots，\\omega_t=i,\\omega_{t+1}=j|\\lambda)=p(x_1,\\cdots,x_t,x_{t+1},\\omega_1，\\cdots，|\\omega_t=i,\\omega_{t+1}=j\\lambda)p(\\omega_t=i,\\omega_{t+1}=j|\\lambda)$  \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=p(x_1,\\cdots,x_t,\\omega_1，\\cdots，|\\omega_t=i,\\lambda)p(x_{t+1}|\\omega_{t+1}=j,\\lambda)p(\\omega_t=i,\\omega_{t+1}=j|\\lambda)$(有状态发射的独立性可得)  \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=p(x_1,\\cdots,x_t,\\omega_1，\\cdots，|\\omega_t=i,\\lambda)p(x_{t+1}|\\omega_{t+1}=j,\\lambda)p(\\omega_{t+1}=j|\\omega_t=i，\\lambda)p(\\omega_t=i|\\lambda)$  \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=p(x_1,\\cdots,x_t,\\omega_1，\\cdots，\\omega_t=i|\\lambda)p(x_{t+1}|\\omega_{t+1}=j,\\lambda)p(\\omega_{t+1}=j|\\omega_t=i，\\lambda)$   \n",
    "     \n",
    "   $\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\delta_{t}(i)b_{x_{t+1}}(\\omega_{t+1})a_{ij}$  \n",
    "     \n",
    "   $\\alpha_{t+1}(j)=\\underset{i}{max}\\;\\;\\;\\delta_{t}(i)b_{x_{t+1}}(\\omega_{t+1})a_{ij}$(得到递推公式)  \n",
    "     \n",
    "   之后在最后一个时刻，选择最大的状态，回溯就可以找到最优隐状态序列  \n",
    "     \n",
    "   观测序列较长，一系列小于1的数相乘，最后可能会导致下溢出。改进基于对数的Viterbi算法  \n",
    "     \n",
    "![](../../img/Pattern_recognition/proba_model/pro8.PNG)  \n",
    "  \n",
    "    \n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "### 学习问题  \n",
    "给定观测序列样本$X^T=\\{x_1,x_2,\\cdots,x^t\\}$;我们用这个观测序列，训练一个模型$\\lambda=\\{\\pi,A,B\\}$；训练的目标是$p(X|\\lambda)$;即使用这个模型产生这个观测序列的概率最大（$\\pi$是隐状态的初始概率，A是隐状态的转移概率，B是隐状态发射观测变量的概率）。  \n",
    "  \n",
    "* Baum-Welch 算法（向前向后算法）。  \n",
    "E-M 推导过程：  \n",
    "目标是求$p(X|\\lambda)$最大：  \n",
    "1、隐变量是未知变量，所有未知变量取值的组合就是未知变量期望的分布值。这里也就是所有路径的组合记为$\\Omega$  \n",
    "2、对所有样本求参数$\\lambda$的极大似然：$ln \\;p(x^T,\\Omega_i|\\lambda)$  \n",
    "3、对未知变量取值可能求期望：$E_\\Omega[ln\\;p(x^T,\\Omega_i|\\lambda)]=\\sum_{\\Omega}ln\\;p(x^T,\\Omega_i|\\lambda)*p(x^T|\\Omega_i,\\lambda)$  \n",
    "4、$p(x^T|\\Omega_i,\\lambda)=\\frac{p(x^T ,\\Omega_i,\\lambda)}{p(\\Omega_i|\\lambda)}=\\frac{\\alpha_{t-1}(i)b_{x_t}(\\omega_t)a_{ij}\\beta_(t)}{p(\\Omega_i|\\lambda)} \\; @ \\gamma_{ij}(t) \\;$（隐状态序列$\\{\\omega_1,\\cdots,\\omega_T\\}$=在t时刻$\\{\\omega_1,\\cdots,\\omega_t\\}$的前向概率和$\\{\\omega_t,\\cdots,\\omega_T\\}$的后向概率?）  \n",
    "5、$Q(\\lambda)=\\sum_{\\Omega}ln\\;(\\alpha_{t-1}(i)b_{x_t}(\\omega_t)a_{ij}\\beta_(t))*\\gamma_{ij}(t) \\quad$)  \n",
    "6、$\\lambda^{t+1}=\\underset{\\lambda}{arg\\;max}\\;\\;Q(\\lambda^T)$  \n",
    "7、任然存在路径组合爆炸的情况；所以使用前向，先后向算法求路劲；对 $a_{ij}$要求平均；$$\\hat{a_{ij}}=\\frac{\\sum_{t=1}^T \\gamma_{ij}(t)}{\\sum_{t=1}^T\\sum_{j=k}\\gamma_{ij}(t)}$$  \n",
    " 8、对 $b_{jk}$要求平均；$$\\hat{b_{jk}}=\\frac{\\sum_{t=1}^T\\sum_{j=k,v(t)=k}\\gamma_{ij}(t)}{\\sum_{t=1}^T\\sum_{j=k}\\gamma_{ij}(t)}$$  \n",
    " 9、细致推导（参见图片pro9.png）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
