{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AP 聚类  \n",
    "  \n",
    "* 算法流程  \n",
    "    1、初始化$a(i,k)$为0  \n",
    "      \n",
    "    2、更新$r(i,k)$矩阵  \n",
    "      \n",
    "    $\\qquad r(i,k)=\\begin{cases} s(i,k)-\\underset{k' \\neq k}{max} \\{a(i,k')+s(i,k')\\}, & i \\neq k\\\\ s(i,k)-\\underset{k' \\neq k}{max}\\;\\; s(i,k'), & i = k \\end{cases}$   \n",
    "      \n",
    "    3、更新 $a(i,k)$矩阵  \n",
    "      \n",
    "   $\\qquad\\quad a(i,k)=\\begin{cases} {min} \\{0,\\;\\; r(k,k)+\\underset{i'\\notin (i,k)}{\\sum}max \\{0,r(i',k)\\;\\}\\;\\;\\}, & i \\neq k\\\\ \\underset{i'\\notin (i,k)}{\\sum}max \\{0,r(i',k)\\;\\}\\;\\;, & i = k \\end{cases}     $    \n",
    "     \n",
    "    4、衰减系数$\\lambda$进行衰减  \n",
    "      \n",
    "    $\\qquad\\quad r_{t+1}(i,k)=\\lambda * r_{t}(i,k) +(1-\\lambda) * r_{t+1}(i,k)$  \n",
    "      \n",
    "    $\\qquad\\quad a_{t+1}(i,k)=\\lambda * a_{t}(i,k) +(1-\\lambda) * a_{t+1}(i,k)$   \n",
    "      \n",
    "    5、重复2，3,4直至矩阵稳定或者达到最大迭代次数，算法结束。  \n",
    "      \n",
    "    6、最总选择 a(i,k)+r(r,k) 最大的k值为聚类中心    \n",
    "      \n",
    "        \n",
    "<br>  \n",
    "  \n",
    "\n",
    " \n",
    "$a(i,k)$整体表明原型K认为自己适合作为i的原型的程度，其最大值为0，完全认为自己适合作原型，当负数越小越表明自己不适合作i的原型 \n",
    "   \n",
    "从$r(i,k)$公式可以看出 :  （一开始a(i,k）为0） 首先s(i,k)是负平方损失，如果i选择k,比选择其他k'更适合，那么s(i,k)比s(i,k’)更大，那么r(i,k)就是正的,选择k是合适的， 反之就是 负的。  也就是说 r(i,k)表示i选择k做原型时，选择的好 就是正，选择的不好就是 负的 ；之后 a(i,k)的取值范围时$（-\\infty,0）$,越接近0，表明原型越适合作为i的原型，所以$r(i,k)$更新时，就要确认i和k 的相似度 是否要比i和k'的相似度 加上 k'适合作为i的原型的可能性还要大   \n",
    "  \n",
    " $r(k,k)$为负：表明k点目前更适合作为属于另一个原型而不是作为一个原型本身   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "$r(i,k)=$ i和k的相似性 $\\;\\;$ 是否大于（>）$\\;\\; $ i选择k'的合适程度$\\;\\;$(i选择k'的合适程度 =  k'认为自己适合i的程度 $\\;\\;$加上$\\;\\;$ i和k'的相似性)  \n",
    "  \n",
    " ![](../../img/Pattern_recognition/clustering/AP1.PNG)    \n",
    "   \n",
    "<br>    \n",
    "  \n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "  \n",
    "<br>    \n",
    "  \n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "\n",
    "###   AP 聚类 (关联传播) \n",
    " \n",
    " 基于相似性度量的数据聚类。一种常用的方法是类似于k-means，用使用数据去学习一组数据中心，让数据点和其最近的数据中心的误差平方和最小。这些中心称为‘原型’  \n",
    "   \n",
    "<br>  \n",
    "  \n",
    "AP聚类 ：采用了一种完全不同于上诉描述的方法。  \n",
    "   \n",
    "AP聚类 ： 同时考虑把所有数据点作为潜在的原型样本。  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$通过把每一个数据点视作网络中的一个节点，然后AP聚类递归的沿着网络的边缘传递数据点的实值信息，直到一组好的原型和相应的聚类出现为止。   \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$ 传递的实值消息，是在寻找效用函数最小值的基础上更新的。  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$ 在任何时间点，传递实值消息的大小，都反应了一个数据点选择另一个数据点作为其原型的合适程度（关联程度）。   \n",
    "  \n",
    "<br>  \n",
    "   \n",
    "AP聚类 ：把数据点的之间的相似性矩阵作为输入 。  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$ 相似矩阵$S(i,k)$表示数据点k作为数据点i的原型的合适程度。当目标是最小化平方误差时，每一个相似度是负平方误差，如$s(i,k)=-||x_i-x_k||^2$    \n",
    "\n",
    "$\\qquad\\quad\\;\\;$当模型是一个原型依赖的概率模型时，相似度矩阵$S(i,k)$可以设置为数据点i的原型为数据点k的极大似然值。  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "AP聚类 ：聚类簇的个数并不是事先设定的。 而是事先设置每个点的$S(k,k)$的实值作为输入，其中各个点的$S(k,k)$中，较大值对应的数据点更可能被选作原型  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$这些较大值对应的数据点，叫做首选项。最后的聚类个数受到这些首选项的影响。（也就是事先设置的$S(k,k)$是选某个点作为原型的先验知识或偏好  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$ 之后还要受到信息传递的影响），如果先验知识所有数据都适合做原型所有$S(k,k)$设置一个公共值， 这个公共值的改变，会改变最终聚类的个数。  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$这个共享值可以是输入相似性的中位数(导致集群数量适中)，也可以是输入相似性的最小值(导致集群数量较少)。  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "<br>\n",
    "  \n",
    "AP聚类 ： 数据点之间有两种信息的交换,(每一种信息都考虑到了不同的竞争)   \n",
    "  \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$ $r(i,k)$的责任是，从数据点i发送信息到i的候选原型点k，其信息是相比较其他候选原型点k'，原型点k作为数据点i的原型的累计证据（适合程度）。   \n",
    "  \n",
    "$\\qquad\\quad\\;\\;$  $a(i,k)$的作用是，从候选原型点k发送信息到数据点i，其信息是原型点k作为数据点i的累计证据（合适程度），考虑到其他数据点也选择k做原型  \n",
    "    \n",
    "    \n",
    "<br>     \n",
    "     \n",
    "<br>  \n",
    "\n",
    "![](../../img/Pattern_recognition/clustering/AP3.PNG)   \n",
    "    \n",
    "<br>  \n",
    " \n",
    "图B:$r(i,k)$的责任是从数据点i发送到候选原型，并指示出每个数据点如何强烈地支持候选原型k而不是其他候选原型k'  \n",
    "  \n",
    "图C:“可用性”$a(i,k)$ 是从候选原型k'发送到数据点i，并指示每个候选原型k'作为数据点i的聚类中心可用的程度    \n",
    "  \n",
    "    \n",
    "<br>   \n",
    "  \n",
    "总结： $r(i,k)$的责任是，数据点i,相比较其他候选原型k’，选择候选原型k的累计证据，并把它从数据点i发给候选原型k。（角度是从数据点到候选原型）  \n",
    "  \n",
    "  $a(i,k)$表示的是，候选原型k,可以用作数据点的i的原型的可能性多大，并把它从候选原型k发送到数据点i。（角度是从候选原型到数据点）\n",
    "       \n",
    "<br>  \n",
    "\n",
    "$r(i,k)$更新允许所有候选原型竞争数据点的所有权，a(i,k)更新从数据点收集证据，以确定每个候选原型是否会成为一个好的原型  \n",
    "  \n",
    " \n",
    "     \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "![](../../img/Pattern_recognition/clustering/AP1.PNG)  \n",
    "![](../../img/Pattern_recognition/clustering/AP2.PNG)   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "工作过程聚类原型的形成：相似性使用负平方误差，每个点都根据它是一个集群中心的当前证据着色，从绿色渐变到红色（从非原型渐变到原型），从点i指向点k的箭头的暗度对应于传输的消息的强度，点i属于聚类中心点k的强度。    \n",
    "  \n",
    "  \n",
    "<br>  \n",
    "   \n",
    "<br>  \n",
    "  \n",
    "AP聚类流程：  \n",
    "  \n",
    "  首先设置$a(i,k)$：设置$a(i,k)=0$，即一开始把每个候选原型可以作为数据点的聚类中心的可能性设为0  \n",
    "    \n",
    "  然后计算数据点选择某个候选原型的可能：$r(i,k)=s(i,k)-\\underset{k' \\neq k}{max} \\{a(i,k')+s(i,k')\\}$   \n",
    "   \n",
    "       在第一次迭代中：由于a(i,k)=0，所以r(i,k) 被设置为r(i,k) 减去  i 选其他候选原型中最大的相似性。    \n",
    "         \n",
    "       后续迭代中，当数据点被有效分配给其他原型时，他们的a(i,k)会按照接下来给的规则，下降到0一下  \n",
    "         \n",
    "       负的a(i,k')会减少相似性s(i,k')，从而使候选原型k'从竞争原型中删除   \n",
    "         \n",
    "       对于k=i , r（k，k）被设置为输入首选项 前去 k和其他i的最大相似性，r(k,k)反映了基于输入偏好，k作为一个原型的累计证据 ，k是怎么  \n",
    "       \n",
    "       样 不适合分配给其他原型  \n",
    "          \n",
    "  \n",
    "从$r(i,k)$公式可以看出 :  （一开始a(i,k）为0） 首先s(i,k)是负平方损失，如果i选择k,比选择其他k'更适合，那么s(i,k)比s(i,k’)更大，那么r(i,k)就是正的， 反之就是 负的。  也就是说 r(i,k)表示i选择k做原型使，选择的好 就是正，选择的不好就是 负的  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "  $r(k,k)$为负：表明k点目前更适合作为属于另一个原型而不是作为一个原型本身\n",
    "  \n",
    "<br>  \n",
    "         \n",
    "   \n",
    " $a(i,k)$从数据点收集k做为原型的好坏程度：$a(i,k)={min} \\{0,\\;\\; r(k,k)+\\underset{i'\\notin (i,k)}{\\sum}max \\{0,r(i',k)\\;\\}\\;\\;\\}$   \n",
    "   \n",
    "$\\qquad\\qquad\\;\\;\\; r(k,k)+\\underset{i'\\notin (i,k)}{\\sum}max \\{0,r(i',k)\\;\\}\\;$ 表明了k作为原型的适合程度 $\\;\\;$ 加上$\\;\\;$  所有积极选择k做原型的样本的证据之和  \n",
    "  \n",
    "$\\qquad\\qquad\\;\\;\\; a(i,k)={min} \\{0,\\;\\; r(k,k)+\\underset{i'\\notin (i,k)}{\\sum}max \\{0,r(i',k)\\;\\}\\;\\;\\}$ 整体表明原型K认为自己适合作为i的原型的程度，其最大值为0，完全认为自己适合作原型，当负数越小越表明自己不适合作i的原型   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "$a(k,k)$的更新方式：$a(k,k)=\\underset{i'\\notin (i,k)}{\\sum}max \\{0,r(i',k)\\;\\}\\;\\;$这条信息反映了k点是一个原型 积累证据。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
