{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偏差-方差 分解  \n",
    "用来解释学习算法的泛化性能  \n",
    "  \n",
    " 来自同一个的分布的不同训练集,上进行学习得到学习算法也可能不同。  \n",
    "   \n",
    " 对测试样本x,令$y_D$为x在数据集上的标记，y是样本x的真实标记，（存在噪声可能是$y_D \\neq y \\quad$所以等式不成立的时候$y_D$就是噪声）  \n",
    "   \n",
    " $f(x;D)$是在数据集D上学到的算法，在x上的预测。  \n",
    "   \n",
    " 回归例子：$f(x;D)$是在数据集D上学到的算法，在x上的预测。\n",
    "   \n",
    " 对一个样本x,它的期望预测为：$\\hat{f}(x)=E_D[f(x;D)] \\qquad$ 不同数据集D 服从的分布\n",
    "   \n",
    " 使用样本数相同的不同训练集产生的方差为：(不同数据集D 服从的分布)  \n",
    "   \n",
    " 方差：$var(x)=E_D[(f(x;D)-\\hat{f}(x))^2]$   \n",
    "   \n",
    " 噪声：$\\epsilon^2=E_D[(y_D -y)^2] \\qquad$假定噪声期望为0，$E_D[(y_D -y)]=0$    \n",
    "   \n",
    " 偏差（期望预测与它的真实值的差别）：$bias^2(x)=(\\hat{f}(x)-y)^2$    \n",
    "   \n",
    " 期望泛化误差：  \n",
    "  \n",
    "  $E(f;D)=bias^2(x)+var(x)+\\epsilon^2$  \n",
    "    \n",
    " <br>  \n",
    "   \n",
    "  \n",
    "偏差：学习算法的期望预测与真实值得偏离程度；刻画了学习算法的拟合能力。  \n",
    "  \n",
    "方差：度量了同样大小的训练集变动所导致的学习性能的变化   \n",
    "  \n",
    "噪声：泛化下界，刻画了学习任务的难度。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
