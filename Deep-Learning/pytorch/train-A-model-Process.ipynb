{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 损失函数\n",
    "\n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 求导  \n",
    "\n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 优化  \n",
    "\n",
    "梯度下降算法：总的损失函数$f(x)=\\frac{1}{n} \\sum_{i=1}^n f_i(x) \\quad$求出的梯度$\\Delta f(x)=\\frac{1}{n} \\sum_{i=1}^n \\Delta f_i(x) \\quad$  进行迭代 $x \\leftarrow x - \\eta \\Delta f(x)$ 。  \n",
    "  \n",
    "<br>  \n",
    " \n",
    "随机梯度下降算法：迭代是随机选择一个样本损失函数的梯度。$x \\leftarrow x - \\eta \\Delta f_i(x)$  \n",
    "  \n",
    "<br>  \n",
    " \n",
    "pytorch优化算法的总结： \n",
    " \n",
    "框架：\n",
    "\n",
    "目录:\n",
    "\n",
    "\n",
    "$\\quad$torch.optim：首先这是一个库，这个库里包含了各种已经定义好的优化算法（如SGD，Adm）。   \n",
    "  \n",
    "$\\quad$optimizer对象： optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9) ； \n",
    "$\\qquad\\qquad\\qquad\\;\\;\\;$这个对象能保持当前参数的状态(当前迭代步数值)，并基于计算得到的梯度（这个梯度不是用这个对象里算法计算的）进行参数更 $\\qquad\\qquad\\qquad\\;\\;\\;$ 新（下一个迭代步的参数状态） \n",
    "  \n",
    "如何使用optim对象： \n",
    " \n",
    "\n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用pytorch训练一个模型的流程  \n",
    "\n",
    "1、定义优化算法：optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9) ；  \n",
    "$\\qquad$ optimizer里有需要优化的参数。  \n",
    "2、定义模型\n",
    "  \n",
    " 循环：  \n",
    "$\\qquad$ 1、取得样本数据、标签  \n",
    "$\\qquad$ 2、清空梯度  \n",
    "$\\qquad$ 3、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9) \n",
    "model=model()\n",
    "loss_fn()\n",
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()  # 清空所有被优化过的Variable的梯度.\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
