{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＧＡＮ  \n",
    "  \n",
    "#### 自编码器  \n",
    "<img src=\"../img/GAN/GAN1.PNG\"  width=\"300\" hight=\"300\"/>\n",
    "  \n",
    "$h=f(x) \\quad r=g(h)$    \n",
    "   \n",
    " \n",
    "有损拷贝：  $g(f(x)) \\approx x$   \n",
    "  \n",
    "目的：得到中间编码h   \n",
    "  \n",
    "  1、提取特征  \n",
    "    \n",
    "  2、无监督学习  \n",
    "    \n",
    "      \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "#### 自编码器推广    \n",
    "  \n",
    "<img src=\"../img/GAN/GAN2.PNG\"  width=\"300\" hight=\"300\"/>\n",
    "  \n",
    " 自编码器是确定性映射的编码函数 ：$h=f(x) \\quad r=g(h)$   \n",
    "     \n",
    "<br>  \n",
    "  \n",
    "      \n",
    " 从确定性映射推广大随机映射 ：中间的编码函数是某个分布函数(这个前馈网络能对应某个分布)  \n",
    "\n",
    "从前馈网络产生编码：$h=f(x)$    \n",
    "  \n",
    "变成从前馈网络产生条件分布：$P_{encoder}(h|x)$  \n",
    "  \n",
    "$P_{encoder}(h|x) \\qquad P_{dencoder}(r|h) $   \n",
    "  \n",
    "通过采样得到满足条件分布的数据样本  \n",
    "  \n",
    "<br>    \n",
    "  \n",
    "参考变分自编码器：  \n",
    "  \n",
    "由隐变量模型$P_{model}(h,x)$定义随机编译码分布：$P_{encoder}(h|x) = P_{model}(h|x)  \\qquad P_{dencoder}(r|h)=P_{model}(r|h) $   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "编码器译码器的训练：判别准则  \n",
    "  \n",
    "1、输入输出相同：编码、提取特征   \n",
    "  \n",
    "2、输入输出分布尽可能相同：逼近真实数据分布  \n",
    "    \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "#### GAN      \n",
    "  \n",
    "GAN神经网络，生成器与判别器的对抗，让生成器达到我们的要求。生成器生成的数据一开始不正确，让判别器修正，相互提高。判别器提高识别数据的概率（对抗生成器），生成器提高生成真数据的概率（对抗判别器）   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "产生器：参考VAE    \n",
    "  \n",
    "判别器：普通判别器Y=f(x)；P(Y|X)   \n",
    "  \n",
    "  \n",
    "![](../img/GAN/GAN3.PNG)    \n",
    "  \n",
    "目的：用模型分布$P_{model}(x)$ 参数为$\\theta$逼近真实的数据分布$P_{data}(x) \\quad$有了p(x),就可以根据p(x)抽样出所有的样本。    \n",
    "  \n",
    "    \n",
    "基于博弈论：生成器与判别器的博弈  \n",
    "  \n",
    "  产生器：以假乱真，产生数据  $\\hat{x}=g(z;\\theta^g)$\n",
    "    \n",
    "  判别器：识别数据，数据为真的概率 $d(x;\\theta^d)$  \n",
    "    \n",
    "  \n",
    " <br>  \n",
    "   \n",
    " <br>  \n",
    "  \n",
    "#### 零和博弈：没有赢家的博弈，以对方的损失为代价   \n",
    " \n",
    "   \n",
    " 判别器效用函数（加大识别真数据的概率d(x)，减小识别假数据分布$p_{model}$产生的样本概率$d(\\hat{x})$等于加大$1-d(\\hat{x})$的概率 ）总体上就是最大化这个式子：  \n",
    " $\\qquad\\qquad V(\\theta^g,\\theta^d)=E_{x\\text{~}pdata} log \\;d(x) + E_{x\\text{~}pmodel} log \\;(1-d(\\hat{x}))$   \n",
    "   \n",
    " \n",
    "   \n",
    " 生成器效用函数(与判别器刚好相反，减少真数据概率，增大假数据的概率)： $-V(\\theta^g,\\theta^d)$   \n",
    "   \n",
    "   \n",
    "博弈结果:最大化判别器的结果，再对这个结果最小化 $\\quad g^* \\;=\\; \\underset{g}{ arg\\;\\;min}\\underset{d}{\\;\\;max\\;\\;} V(\\theta^g,\\theta^d)$  \n",
    "    \n",
    "最理想的结果就是：判别器无法识别生成器生成的数据(0.5随机猜测)$d(\\hat{x})=0.5$   \n",
    "  \n",
    "  \n",
    "    \n",
    "<br>   \n",
    "\n",
    "$V(\\theta^g,\\theta^d)$函数具体是什么样的，d(x)函数具体是什么样的？\n",
    "\n",
    "<br> \n",
    "\n",
    "* 零和博弈问题：  \n",
    "    $V(\\theta^g,\\theta^d)$根据若是非凸函数，怎么求最优值  \n",
    "      \n",
    "        \n",
    " <br>   \n",
    "   \n",
    " <br>  \n",
    "     \n",
    "  固定参数的迭代优化\n",
    "  \n",
    "  识别器训练k次(识别器最大化识别真数据概率，最大化不能识别假数据概率)，生成器训练一次（生成器只需要最大化识别器错误识别生成器生成数据的概率）      \n",
    "       \n",
    "* 算法流程：     \n",
    "   \n",
    "   总体迭代次数：\n",
    "    \n",
    "  训练K次识别器：  \n",
    "     \n",
    "  m个真数据，m个假数据，此时生成器参数$\\theta^g$固定;训练识别器：$\\frac{\\partial V}{\\partial \\theta^d} \\;=\\;\\frac{1}{m} \\sum_{i=1}^m \\; [\\; log \\;d(x^i) \\;+\\; log \\;(1-d(\\hat{x^i}))]$  \n",
    "    \n",
    "  训练K次识别器后，训练一次生成器，此时重生成m个假数据：$\\frac{\\partial V}{\\partial \\theta^g} \\;=\\;\\frac{1}{m} \\sum_{i=1}^m \\; [\\; log \\;(1-d(\\hat{x^i}))]$  \n",
    "        \n",
    "   <br>  \n",
    "     \n",
    "   参数更新，带动量的梯度更新\n",
    "  \n",
    "  ![](../img/GAN/GAN4.PNG)\n",
    "  \n",
    "        \n",
    "          \n",
    "<br>  \n",
    "  \n",
    "<br>   \n",
    "  \n",
    "<br>  \n",
    "\n",
    "#### GAN分析  \n",
    " ![](../img/GAN/GAN5.PNG)  \n",
    "   \n",
    "黑色点线：是真实数据的概率分布$P_{data}(X) \\qquad$ ;绿色实线：是生成数据的概率分布$P_g(X) \\qquad$ ;蓝色点线：识别器的识别率：$d(x)$  \n",
    "  \n",
    "黑色水平线Z:是生成数据隐变量的采样分布，的取值域 （这里隐变量的采样分布是均匀分布）$\\qquad$  上面的水平线X：是真实数据X的取值域   \n",
    "  \n",
    "向上箭头：是一种映射X=G(Z),将一种分布取值映射到另一种分布  \n",
    "  \n",
    "图a:是一个接近收敛的对象，$p_g \\approx p_{data}$,但是预测d(x)不准确  \n",
    " \n",
    "图b:再内循环中，D收敛到最佳值   \n",
    "  \n",
    "图c:更新$\\theta^g$, $p_g $更接近$p_{data}$,   \n",
    "  \n",
    "图d:达到最优值$p_g = p_{data}$ ，d(x)=0.5   \n",
    "  \n",
    "    \n",
    "<br>   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "* 最优值的推导：  \n",
    "    $\\qquad\\qquad V(\\theta^g,\\theta^d)=E_{x\\text{~}pdata} log \\;d(x) + E_{x\\text{~}pmodel} log \\;(1-d(\\hat{x}))$  \n",
    "      \n",
    "    $\\qquad\\qquad \\qquad\\quad\\;\\;=\\int_x P_{data}(x)\\; log \\;d(x) \\;\\;dx + \\int_x p_z(z) log \\;(1-d(G(z)))\\;\\;dz$  \n",
    "      \n",
    "    $\\qquad\\qquad \\qquad\\quad\\;\\;$最优值时$p_g = p_{data}$   \n",
    "      \n",
    "    $\\qquad\\qquad \\qquad\\quad\\;\\;=\\int_x [\\;\\; P_{data}(x)\\; log \\;d(x) \\; +  p_g(x) log \\;(1-d(x))\\;\\;]\\;dx$  \n",
    "      \n",
    "    $\\qquad\\qquad \\qquad\\quad\\;\\;$欧拉方程：$\\frac{\\partial  [\\;\\; P_{data}(x)\\; log \\;d(x) \\; +  p_g(x) log \\;(1-d(x))\\;\\;]}{\\partial d}$  \n",
    "      \n",
    "     $\\qquad\\qquad \\qquad\\quad\\;\\; = \\frac{P_{data}(x)}{d(x)} - \\frac{P_g(x)}{1-d(x)}=0$  \n",
    "         \n",
    "     $\\qquad\\qquad \\qquad\\quad\\;\\; d^*= \\frac{P_{data}(x)}{P_{data}(x)+P_g(x)} $    \n",
    "       \n",
    "         \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "### GAN 总结  \n",
    "   \n",
    "     \n",
    " 1、生成器G的梯度更新信息，来源于判别器D,而不是自身，或样本。  \n",
    "   \n",
    " 2、训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但我认为在实践中它还是比训练玻尔兹曼机稳定的多  \n",
    "   \n",
    " 3、GAN不适合处理离散形式的数据，比如文本  \n",
    "   \n",
    "4、GAN存在训练不稳定、梯度消失、模式崩溃的问题（目前已解决）  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "模式崩溃(model collapse)原因\n",
    "\n",
    "一般出现在GAN训练不稳定的时候，具体表现为生成出来的结果非常差，但是即使加长训练时间后也无法得到很好的改善。\n",
    "\n",
    "具体原因可以解释如下：GAN采用的是对抗训练的方式，G的梯度更新来自D，所以G生成的好不好，得看D怎么说。具体就是G生成一个样本，交给D去评判，D会输出生成的假样本是真样本的概率（0-1），相当于告诉G生成的样本有多大的真实性，G就会根据这个反馈不断改善自己，提高D输出的概率值。但是如果某一次G生成的样本可能并不是很真实，但是D给出了正确的评价，或者是G生成的结果中一些特征得到了D的认可，这时候G就会认为我输出的正确的，那么接下来我就这样输出肯定D还会给出比较高的评价，实际上G生成的并不怎么样，但是他们两个就这样自我欺骗下去了，导致最终生成结果缺失一些信息，特征不全。  \n",
    "      \n",
    "        \n",
    "<br>  \n",
    "  \n",
    "    \n",
    "为什么GAN不适合处理文本数据\n",
    "\n",
    "文本数据相比较图片数据来说是离散的，因为对于文本来说，通常需要将一个词映射为一个高维的向量，最终预测的输出是一个one-hot向量，假设softmax的输出是（0.2， 0.3， 0.1，0.2，0.15，0.05）那么变为onehot是（0，1，0，0，0，0），如果softmax输出是（0.2， 0.25， 0.2， 0.1，0.15，0.1 ），one-hot仍然是（0， 1， 0， 0， 0， 0），所以对于生成器来说，G输出了不同的结果但是D给出了同样的判别结果，并不能将梯度更新信息很好的传递到G中去，所以D最终输出的判别没有意义。  \n",
    "  \n",
    "    \n",
    "<br>  \n",
    "  \n",
    " 另外就是GAN的损失函数是JS散度，JS散度不适合衡量不想交分布之间的距离。\n",
    "\n",
    "（WGAN虽然使用wassertein距离代替了JS散度，但是在生成文本上能力还是有限，GAN在生成文本上的应用有seq-GAN,和强化学习结合的产物）  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
