{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adversial-AotoEncoder(AAE)  \n",
    "\n",
    "## 摘要  \n",
    "   \n",
    "   本文提出对抗自编码器（AAE）,这是一个概率自编码器。它通过使用GAN网络匹配一个任意的先验分布和编码向量z的聚合后验分布，来完成VAE的变分推断。  \n",
    "   把聚合后验分布匹配到先验分布的目的是确保从先验分布中产生的样本是有意义的。  \n",
    "     \n",
    "   即AAE得解码器是一个深度生成模型，它把先验分布映射到数据分布。  \n",
    "     \n",
    "   本文展示了AAE如何应用于诸如半监督分类、分离样式和图像内容、无监督聚类、降维和数据可视化等应用。  \n",
    "     \n",
    "<br>  \n",
    "\n",
    "## 简介  \n",
    "  \n",
    "  构建可扩展的生成模型来获取像音频、图像或视频这样丰富的分布，是机器学习的主要挑战之一。直到最近，深度生成模型（如受限的玻尔兹曼机(RBM)，深度信念网络(DBNs)和深度玻尔兹曼机(DBMs)，主要是基于MCMC算法训练的。    \n",
    "    \n",
    " **在这些方法中，随着训练的进行，MCMC方法计算log似然梯度变得更加不精确。这是因为来自马尔可夫链的样本不能很快地在模式之间混合。**   \n",
    "   \n",
    " **近年来，已经开发出了可以通过直接反向传播训练的生成模型，并避免了MCMC训练带来的困难。例如,（变分自编码(VAE)或重要性加权自编码器，使用一个识别网络预测潜在变量的后验分布)。（ 生成对抗网络(GAN)使用一个对抗的训练过程通过反向传播直接拟合网络的输出的分布）。（生成矩匹配网络(GMMN)使用一个时刻匹配代价函数来学习数据分布。)**   \n",
    "   \n",
    " 在本文中，我们提出了一种通用的方法，称为对抗自编码(AAE)，可以将自动编码器转换成生成模型。  \n",
    "   \n",
    " **在我们的模型中，一个自编码器接受双重训练目标——一个传统的重构误差标准，以及一个对抗训练标准，它将变分自编码器的潜在表示z的聚合后验分布与一个任意的先验分布相匹配。**    \n",
    "   \n",
    " 我们证明这个训练标准与VAE训练有很强的联系。训练的结果是encoder学习将数据分布转换为先验分布，同时decoder学习一个深度生成模型，该模型将先验映射到数据分布。    \n",
    "   \n",
    "<br>  \n",
    "  \n",
    "## 对抗生成网络GAN  \n",
    "  \n",
    "  $$\\underset{G}{min}\\;\\underset{D}{max} E_{x\\text{~}P_{data}}[log D(x)]+E_{x\\text{~}P_{z}}[log （1-D(G(z))）] $$  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "## 对抗自编码器(adversial-AotoEncoder AAE)    \n",
    "  \n",
    "  AAE的网络结构图：  \n",
    "    \n",
    "![](img/1.PNG)\n",
    "   \n",
    "   设X是输入样本，Z是深度自编码器的潜在编码向量。$p(z)$是我们想要加在编码z上的先验分布。$q(z|x)$是编码分布。$p(x|z)$是解码分布。让$p_d(x)$作为数据的真实分布。让$p(x)$作为模型分布。  \n",
    "     \n",
    "   自编码器的编码函数 $q(z|x)$定义在编码向量z上。q(z)的聚合后验分布为：  \n",
    "   $$q(z)=\\int_x q(z|x)q_d(x) dx$$  \n",
    "     \n",
    " 对抗自编码器AAE，通过匹配聚合后验q(z)到任意的先验 p(z)来实现正则化。**对抗网络被附加在AE的隐编码上。**   \n",
    "   \n",
    " 对抗网络用来引导q(z)匹配 p(z)，同时，AE试图将重建误差最小化。 对抗网络的生成器是AE的encoder q(z|x)， encoder确保聚合后验分布可以愚弄判别器，让它认为隐编码 q(z)来自真实的先验分布 p(z)。  \n",
    "   \n",
    "  对抗网络和自动编码器都分两个阶段SGD联合训练——每个mini-batch执行重建阶段和正规化阶段。 在重建阶段，AE以最小化输入的重建误差来更新encoder和decoder。 在正规化阶段，对抗网络首先更新判别器，以从生成样本（由AE计算的隐编码）中分离出真实样本（使用先验生成的）， 然后对抗网络更新其生成器（它是AE的encoder），以便混淆判别器。  \n",
    "    \n",
    " 一旦完成训练之后，AE的decoder将定义一个生成模型，将p(z)的聚合先验映射到数据分布。  \n",
    "   \n",
    " * AAE 的encoder q(z|x)有一下几种可能的选择：  \n",
    "   \n",
    "   1、确定性：假设q(z|x)是x的确定性函数。在这种情况下，encoder类似于标准AE的encoder， q(z)中唯一的随机源是数据分布$p_d(x)$。  \n",
    "     \n",
    "   2、高斯后验：这里我们假设q(z|x)是高斯分布，其均值和方差由encoder网络预测：$z_i\\text{~}N(\\mu_i(x),\\sigma_i(x))$。在这种情况下，q(z)中的随机性来自encoder输出端高斯分布的随机性和数据分布。我们可以使用相同的重新参数化技巧来通过encoder网络进行反向传播。  \n",
    "     \n",
    "   3、通用近似后验：AAE可用于训练q(z|x)作为后验的通用逼近器。  \n",
    "     \n",
    "<br>  \n",
    "\n",
    "## AAE与VAE的区别和联系  \n",
    "  \n",
    "  VAE和对抗自动编码器之间的一个重要区别是，在VAEs中，为了通过用蒙特卡罗取样的KL距离来反向传播，我们需要访问先验分布的确切函数形式。 然而，在AAE中，我们只需要从先验分布中抽样，以便诱导q(z)匹配p(z)。 在2.3节中，我们将展示AAE可以施加复杂的分布，而无需访问分布的显式函数形式。   \n",
    "    \n",
    "<br>    \n",
    "\n",
    "<br>\n",
    "\n",
    "## AAE的总结  \n",
    "   \n",
    "   传统编码器输出的属性使我们能够将输入数据转换为有用的表示形式。在使用变分自动编码器的情况下，解码器已受过训练，可以从类似于我们选择的先验样本的样本中重建输入。因此，我们可以从此先验分布中采样数据点，并将其馈送到解码器中，以在原始数据空间中重建逼真的外观数据点。\n",
    "\n",
    "不幸的是，**变分自动编码器通常会在先验分布的空间中留下一些区域，这些区域不会映射到数据中的实际样本。对抗性自动编码器旨在通过鼓励编码器的输出完全填充先验分布的空间来改善此情况，从而使解码器能够从先验采样的任何数据点生成逼真的样本。** 对抗性自动编码器通过使用两个新组件，即鉴别器和生成器，来代替使用变分推理。接下来讨论这些。  \n",
    "   \n",
    " $\\color{red}{\\text{传统的自编码器学得的中间编码特征Z，是没有附加信息的，只是对输入信息的压缩，我们并不知道z对我们聚类任务是否是适合的，}} $   \n",
    " $\\color{red}{\\text{所以我们要对z进行一些限定。VAE对Z做了一些限定，如服从高斯分布。但是这种限定还不够还有如VaDE,GMVAE等更进一步的限定。}} $  \n",
    " $\\color{red}{\\text{而AAE的限定是对VAE的一种弥补}} $  \n",
    "   \n",
    " $\\color{blue}{\\text{想法：可以结合GMVAE和AAE对Z的限定，让学得的Z更适合聚类任务。}}$   \n",
    "   \n",
    "<br>  \n",
    "\n",
    "![](img/1.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
