{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于高斯混合模型的深度聚类算法  \n",
    "  \n",
    "### 摘要  \n",
    "聚类可以在不需要先验知识的情况下自主学习原始数据中隐含的聚类结构。普通的聚类算法对高维数据的聚类效果不佳。本文提出了一种基于高斯混合模型的深度聚类算法，该算法结合了堆叠式自动编码器和高斯混合模型两种模型。该算法利用降维数据特征的期望最大化算法训练高斯混合，并更新数据聚类，使数据在特征空间中聚类。实验结果表明，该算法提高了聚类精度，验证了算法的有效性。  \n",
    "    \n",
    "    \n",
    "    \n",
    "### 引言  \n",
    "如今，随着新兴移动互联网时代的到来和电子商务技术的飞速发展，大量的真实信息被计算机处理，形成大规模的数据，如互联网上的网页信息、医学超声图像、生物技术等。由于大规模、高实时性、复杂的内部数据结构和潜在的相关性，采用传统技术处理这些数据的效果并不理想。由于深度学习是数据驱动的，能够从足够的训练数据中自动学习具有代表性和层次性的抽象特征，而不是手动生成的特征，因此深度学习表现良好[1,2]。深度学习模仿人脑的认知过程进行特征学习，而不是使用传统的人工提取特征的过程[3]。  \n",
    "  \n",
    "在深度学习的许多应用中，大多数训练模型都使用监督学习。但现实世界中的大多数数据都是未标记的，在人工提取的特征上附加标签代价高昂，而且常常伴随着人为错误。因此，无监督学习有望开发出更通用的学习和实验模型，未来仍有巨大的研究空间。聚类分析是机器学习领域一种典型的无监督学习技术。原始数据中通常存在一些隐含的内部模式，而聚类分析是一种探索和发现这些隐含内部模式的技术。聚类方法自动将数据样本集和样本集中的所有样本点分成多个聚类[4]。近年来，随着信息科学技术的不断进步，聚类分析面临的问题越来越多，数据维也越来越高。2006年，Torre[5]将降维和聚类相结合，首先用K均值对数据进行聚类，然后将数据投影到组间方差最大化的低维上。2016年，谢[6]提出了深度嵌入聚类，利用深度神经网络进行非线性特征提取进行聚类分析。    \n",
    "  \n",
    "    \n",
    "**由于深度学习在高维大规模数据集中具有良好的性能，本文将深度学习与聚类相结合，提出了一种基于高斯混合模型的深度聚类算法。该算法通过层叠式自动编码器的隐藏层将原始输入数据转化为抽象特征，然后利用高斯混合模型对未标记特征进行聚类。通过实验对该算法进行了评价，并分析了该算法在不同标准数据集上的性能**    \n",
    "    \n",
    "      \n",
    "### 方法  \n",
    "\n",
    "#### 自编码器  \n",
    "\n",
    "自动编码器在机器学习中非常重要，因为它们在降维后执行信息保存。单层自动编码器是一种只包含一个隐层的神经网络，它将目标值设置为尽可能与输入值相等。深层神经网络使用它作为一个元素，从输入中找到共同的数据表示[7]。单层自动编码器的网络结构如图1所示。输入x通过映射函数转换为特征ℎ，特征ℎ通过另一个映射函数映射到重建数据r。在自动编码器的训练过程中，采用反向传播算法调整网络的权值和偏差，以减小误差值。  \n",
    "  \n",
    "最近在机器学习方面的研究表明，深度或层次结构有助于发现数据中高度非线性和复杂的模式[8]。受这些研究的启发，本文考虑一种由多个自动编码器叠加组合而成的堆叠式自动编码器（SAE）[9]。SAE有两种训练方式：自下而上训练和贪婪分层训练。众所周知，以自底向上训练方式训练的深网络会陷入局部最优[10]。本文选择贪婪学习算法。其关键思想是一次训练一层，后一层从前一个编码器的输出输入[11]。贪婪分层训练也称为预训练。使用标准的反向传播算法在无监督的情况下进行预训练[12]。图2显示了SAE的整体模型，其中有多个分层堆叠的自动编码器。    \n",
    "  \n",
    "#### 高斯混合模型  \n",
    "  \n",
    "高斯混合模型（GMM）是一种广泛应用的聚类算法，它是一个参数概率密度函数，用高斯分量密度的加权和表示[13]。GMM参数由训练好的先验模型用迭代期望最大化（EM）算法估计得到。对于混合模型，假设给定样本x是随机向量的实现，该随机向量的分布是几个类条件分布的混合（凸组合）[14]  \n",
    "  \n",
    "在给定训练数据向量和GMM结构的情况下，采用期望最大化算法迭代估计GMM的参数，使训练后的特征向量在某种意义上紧密分布。对于N个训练向量12={，}nxxxx，假设每个向量相互独立，GMM似然可以写成  \n",
    "  \n",
    "### 基于GMM的深度聚类算法    \n",
    "  \n",
    "  原始空间包含各种复杂的结构，这是一个具有挑战性的问题。传统的方法通过添加特征学习方法来解决这个问题，这些方法要么捕获数据的内在结构，要么表示数据以获得更好的聚类。深度聚类算法使用神经网络学习来促进聚类任务的深层特征表示。在这一部分中，我们使用堆叠式自动编码器与高斯混合模型相结合来训练GMM，并使用期望最大化算法来更新数据簇。基于GMM的深度聚类算法的结构图如图3所示。  \n",
    "    \n",
    " 在这种深度聚类算法中，数据集12{，}N=X×X的每个样本都是D维的。首先，我们建立了一个基于神经网络的堆叠式自动编码器，它由编码器l E和解码器0组成，（），l D l l=，SAE的参数分别为l Dθ和l Eθ，其中l代表堆叠式自动编码器的层数。编码器将输入数据从原始D维数据空间映射到D维空间（D<），解码器l D将特征数据从编码空间映射到原始D维数据空间，通过对编码器和解码器的重构，使每个数据点1，（），nn N=x大致等于（（））nnde≈x x x。如果重建是可行的，自动编码器将压缩每个样本的信息而不会造成太大的损坏。其次，对第一层的自动编码器进行训练后，将第一层的编码作为第二层自动编码器的输入数据，然后对第二层自动编码器进行训练，使该层自动编码器的损耗尽可能小。最后，训练L层自动编码器后，将最后一层的编码数据作为特征12{，}N=H H H H，完成特征提取阶段。在这个过程中，每个自动编码器的统一组合称为堆叠式自动编码器。在特征提取阶段，采用贪婪分层无监督学习方法对每个自动编码器进行训练。     \n",
    "   \n",
    "经过特征提取阶段的训练后，由叠加式自动编码器学习的特征空间数据被送入下一阶段的聚类算法进行聚类。本文采用高斯混合模型作为基本的聚类算法，用来估计给定数据的概率分布。总体分布由几个分量组成，其中簇数K是预先定义的（知道高斯分布的个数K）。12{，，}Kθθθ=定义为高斯混合模型的参数集，其中2（，）1，，（K K K K Kθµσ==表示第K个高斯混合分量的参数。我们使用期望最大化算法来估计每个kθ，也就是说，每个数据都可以用它的概率来表示。如果计算的概率越大，贡献就越大，反之亦然。根据每个样本对高斯分布的贡献作为权重计算加权均值和方差，然后更新高斯分布的原始参数，直到算法收敛到局部最优或最大迭代次数。算法1详细描述了基于GMM网络的深度聚类过程   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
