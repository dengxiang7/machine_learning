{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保留局部结构提升深度集成聚类  \n",
    "\n",
    "  本论文模型：Improved Deep Embedded Clustering(IDEC)\n",
    "  \n",
    "## 摘要  \n",
    "   \n",
    "   深度聚类:用神经网络学习有利于聚类任务的特征表示。  \n",
    "     \n",
    "   一些开创性的工作：同步学习嵌入特征，并且通过明确的聚类损失方向来完成聚类。  \n",
    "     \n",
    "   各种聚类的应用论文都说完成了聚类性能，但是通过对比这些论文发现。  \n",
    "   **$\\color{red}{\\text{在目标函数中定义的聚类损失项可能破坏了特征空间，这可能导致学到一些无意义的特征。而这些特征反过来可能降低聚类的性能}}$**   \n",
    "     \n",
    "   为了解决这个问题：我们提出了保留数据结构的深度集成聚类的性能提升方案。   \n",
    "     \n",
    "   **$\\color{red}{\\text{用一个聚类损失项来引导特征空间分布样本点。\n",
    "   }}$**     \n",
    "     \n",
    "  **本论文模型（IDEC）: 通过整合 聚类损失和自编码器重构损失（来保留数据局部结构），IDEC可以联合优化 1、聚类的标签分配 与 2、用局部数据结构来学习 利于聚类的合适特征。**   \n",
    "    \n",
    "## 引言  \n",
    "    \n",
    "  联合完成聚类和特征学习的深度聚类（Deep cluster）有：DEC  \n",
    "  \n",
    "  DEC：定义的聚类损失被用来同时更新特征提取网络$\\theta$和聚类中心$\\mu$。 在DEC中：标签分配是软分配，但是这里的聚类损失并不能保证数据的局部结构。所以提取的特征可能是有误的。  \n",
    "    \n",
    "  为了避免上述问题。我们做两个假设：1、引导聚类的方向损失。2、保留数据局部结构的机制。  \n",
    "    \n",
    " 本文的主要贡献：  \n",
    "   \n",
    " 1、保留局部数据结构，用来同时完成聚类和特征学习  \n",
    "   \n",
    " 2、证明了在深度聚类中，保持数据的局部结构的重要性。  \n",
    "  \n",
    "  3、IDEC比绝大数方法要好。  \n",
    "    \n",
    "## 相关工作  \n",
    "  \n",
    "### 深度聚类  \n",
    "  \n",
    " * 深度聚类分为两类：  \n",
    "   1、利用神经网络学特征，再用特征学聚类  \n",
    "   2、利用神经网络联合聚类和学习特征    \n",
    "     \n",
    "<br>  \n",
    "\n",
    "### 自编码器  \n",
    "  \n",
    "  编码器:$z=f_w(x)$ ； 解码器：$x'=g_{w'}(z)$  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "* **欠完备自编码器**  \n",
    "   \n",
    "   强制中间特征Z的维度，小于输入x的维度。  \n",
    "     \n",
    "<br>  \n",
    "\n",
    "* **去噪自编码器**   \n",
    "  \n",
    "  目标函数是：$L=||x-g_{w'}(f_w(\\hat{x}))||_2^2$  ； 去噪自编码器输入是：对原始数据$x$添加了噪声的腐蚀数据$\\hat{x}$  \n",
    "      \n",
    "###  Deep Embedded Clustering(DEC)  \n",
    "   \n",
    "   DEC：预训练一个自编码器，然后移除解码器    \n",
    "     \n",
    "   目标函数：  \n",
    "     \n",
    " ![](img/1.PNG)   \n",
    " ![](img/2.PNG)  \n",
    " ![](img/3.PNG)    \n",
    " \n",
    " 分布 Q:同T-分布，度量 样本$x_i$的特征$z_i$，与各个类别的中心$\\mu_i$的相似性。**软分配**  \n",
    "   \n",
    " 分布P:度量了样本$x_i$在所有样本x中属于类别j的概率  ；**这个分布P,是目标分布，目的是从软分配中学到高可靠性分配样本**  \n",
    "   \n",
    " DEC的损失函数中可以，这个模型是一个自训练模型。    \n",
    "   \n",
    "* **DEC的贡献：**  \n",
    "    **DEC的最大的贡献就是聚类损失（更确切的说就是分布P）； 它把高可靠性样本作为监督信号，让每个类别分布中的样本更密集；但是这里的问题是并不能把边缘的样本正确归类。**  \n",
    "    $\\color{red}{\\text{我们处理上面这个问题的方法是：保留数据的局部结构；在这个条件下，高可靠性样本的监督信息，可以保证边缘样本走向正确的分类。}}$  \n",
    "   \n",
    "<br>  \n",
    "  \n",
    "## IDEC   \n",
    "  * **DEC的问题及解决方案：**  \n",
    "    DEC的最大的贡献就是聚类损失（更确切的说就是分布P）； 它把高可靠性样本作为监督信号，让每个类别分布中的样本更密集；但是这里的问题是并不能把边缘的样本正确归类。我们处理上面这个问题的方法是：保留数据的局部结构；在这个条件下，高可靠性样本的监督信息，可以保证边缘样本走向正确的分类。\n",
    "  <br>  \n",
    "  \n",
    "n个样本的数据集$X$,每个样本的维度为d。K个类别。K个聚类中心$\\mu_j$ 。 样本$x_i$的分配标签为$s_i \\in \\{1,2,……，K\\}$。  \n",
    "  \n",
    "**目标是：找到一个好的编码器$f_w$,让样本点的嵌入$z_i$,更适合聚类任务。**    \n",
    "  \n",
    "  神经网络有两部份：1、自编码器 2、DEC的聚类损失 。  \n",
    "  **自编码器部分，被用来当作无监督特征学习。它能在DEC聚类损失的情况下保持数据局部结构。**  \n",
    "    \n",
    "<br>  \n",
    "\n",
    "神经网络：  \n",
    "![](img/4.PNG)  \n",
    "  \n",
    "目标函数： $L= L_r+\\lambda L_c  \\qquad$第一项是重构损失，第二项是聚类损失 。系数$\\lambda >0 $ 控制了对子空间扰动的程度  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "#### 聚类损失和初始化  \n",
    "  \n",
    " * 聚类损失：  \n",
    "  ![](img/1.PNG)   \n",
    "    \n",
    "  Q是T分布测量的软分配。P是从Q分布学到的目标分布。  \n",
    "    \n",
    "<br>  \n",
    "    \n",
    " * 初始化：   \n",
    "**预训练一个堆栈去噪自编码器，然后用编码器获得特征z,用K-means 获得聚类中心$\\mu$**   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "#### 保留数据的局部结构    \n",
    "  \n",
    "  DEC的编码器的嵌入特征z的数据结构并不一定适合聚类任务  \n",
    "    \n",
    "<br>  \n",
    "  \n",
    "#### 优化  \n",
    " \n",
    " 聚类中心，编码器，解码器的优化公式  \n",
    "   \n",
    "![](img/5.PNG)  \n",
    "![](img/6.PNG)\n",
    "![](img/7.PNG)  \n",
    "\n",
    "<br>  \n",
    "  \n",
    "#### 聚类分配    \n",
    "  \n",
    "  $s_i=\\underset{ j }{arg \\; max} \\; q_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
