{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从隐藏的特征学习：联合因素分析和潜在聚类\n",
    "（Bo Yang, Student Member, IEEE, Xiao Fu, Member, IEEE, Nicholas D. Sidiropoulos†, Fellow, IEEE）\n",
    "\n",
    "### 摘要\n",
    "降维技术在数据分析，信号处理和机器学习中起着至关重要的作用。 降维通常在与后续数据分析（例如聚类或分类）分开的预处理阶段中执行。 寻找适合于预期任务的降维表示形式更具吸引力。 本文提出了一个联合因子分析和潜在聚类框架，旨在学习矩阵和张量数据的聚类感知低维表示。 提出的方法利用矩阵和张量分解模型，这些模型产生本质上唯一的数据潜在表示来解散潜在簇结构-否则由于在潜在空间中应用倾斜变换的自由而被掩盖。 同时，将潜在聚类结构用作先验信息以增强分解的性能。\n",
    "   具体贡献包括几个针对模拟的定制问题，相应的算法以及有关收敛特性的讨论。 除了广泛的模拟之外，还使用诸如路透社文档数据和MNIST图像数据之类的实际数据集来展示所提出方法的有效性。  \n",
    "     \n",
    "### 引言\n",
    "当今，许多信号处理和机器学习应用程序都涉及高维原始数据，这些原始数据要求在进行任何进一步处理之前进行适当的压缩。 例如，通常在聚类和分类之前应用降维（DR）。 矩阵和张量分解（或因子分析）分别在矩阵和张量数据的DR中起着重要作用。 传统的分解模型，例如奇异值分解（SVD）和主成分分析（PCA）已被证明在分析高维数据方面是成功的–例如，PCA已在许多应用中用于噪声抑制，特征提取和子空间估计 。 近年来，诸如非负矩阵分解（NMF）[2]，[3]之类的替代模型引起了极大的兴趣（也作为DR工具），因为它们倾向于产生独特且可解释的降维表示。 同时，用于多路数据的张量分解继续在机器学习社区中变得越来越流行，例如，用于社交网络挖掘和潜在变量建模[4] – [8]。\n",
    "   在执行灾难恢复或因素分析时，经常会出现几个关键问题。 首先，应考虑使用哪种类型的因子分析来产生有用的数据表示形式，以进行进一步的处理，例如分类和聚类？\n",
    "   凭直觉，如果数据确实以某种低维表示形式聚集成簇，那么DR应该理想地将输入向量映射到该特定表示-识别正确的子空间是不够的，因为线性变换会扭曲簇结构（参见图1）。  ）。 因此，如果数据遵循唯一的因子分析模型（例如，NMF在某些条件下是唯一的[9]，[10]）并且数据形式在潜在域中成簇，则拟合该因子分析模型将揭示这些簇 。 第二个问题是什么样的先验信息可以帮助获得更好的潜在数据表示形式？ 使用先验信息在实践中有助于抵御噪声和建模错误，因此具有良好的动机。 为此，已经考虑了矩阵和张量分解的各种约束和正则化先验，例如稀疏性，平滑度，单峰性，总变化和非负性[11] – [13]，仅举几例。在这项工作中，我们考虑使用新型的先验信息来辅助因素分析，即潜在聚类结构。 降维数据通常会在聚类任务中产生更好的性能，这表明存在这种动机，这表明数据的聚类结构在某些潜在域中相对于数据域更为明显。\n",
    "   在图2中可以看到一些证据，其中我们比较了来自耶鲁B 2人脸图像数据库和MNIST手写数字图像数据库3的两个图像数据簇的数据点的平均数据域和潜域余弦距离1。 潜在表示是通过NMF产生的。 我们看到，在两种情况下，来自两个不同群集的数据之间的平均潜在域距离显着大于相应的数据域距离。 这种观察促使我们利用这种特性来增强因子分析和聚类的性能。\n",
    "   在[14]，[15]中考虑了使用聚类来辅助基于NMF的DR，其中构建了数据点的距离图，并将其用作NMF的正则化–本质上，它迫使尺寸减小的表示在远处（接近）。 如果高维向量在数据域中较远（分别接近），则为潜在域。 然而，数据域距离和潜域距离不必彼此成正比，如从图2中显而易见的。\n",
    "   为了清楚地看到这一点，请考虑矩阵分解模型X = WH，其中X的每一列代表一个数据点，而H的对应列是其潜在表示。 考虑X的前两列之间的平方距离，即|| X（：，1）−X（：，2）|| 2=（H（：，1）−H（：，2））TWTW（H（：，1）−H（：，2））其中：代表相应参数的所有值。 另一方面，给出了X的前两列的潜在表示的距离$||H（：，1））-H（：，2）||_2^2=(H（：，1））-H（：，2）)^T(H（：，1））-H（：，2）)$注意矩阵WTW如何权衡潜在域距离以产生数据域距离。 另请参见图1。为了充分利用潜在聚类结构，本文提出了一种新颖的联合因子分析和潜在聚类框架。 我们的目标是确定某个域中数据的唯一潜在表示形式，这对于聚类而言是有区别的，并且还使用潜在的群集结构来帮助同时产生更准确的分解结果。 我们提出了几个相关的问题表述，以例证所提出框架的一般性和灵活性，并设计出基于交替优化（即在分解和聚类之间进行交替直到收敛）的相应计算算法。潜在因素的可识别性在我们的方法中起着至关重要的作用，因为它抵消了图1中所示的距离失真效应。这是与相关先前工作（例如[16] – [18]）的主要区别。我们首先使用矩阵和张量数据的几种可识别的因子分解模型进行K均值潜在聚类，即非负矩阵因子分解，基于凸几何（CG）的矩阵因子分解模型[19]和低秩张量因子分解或并行因子分析（  PARAFAC）[20]。 提出了精心设计的优化标准，推导了详细的算法，并讨论了收敛性。 接下来，我们考虑扩展到联合分解和子空间聚类，这是由于子空间聚类的流行[21]。 在审慎设计的模拟中仔细检查了所提出的算法。 使用文档，手写数字和三向电子邮件数据集的实际实验也被用来展示所提出方法的有效性。\n",
    "   \n",
    "  \n",
    "### 方法  \n",
    "问题表述：假设：$X≈WH∈R^{I×J}$ ，对于一些基于元素的非负数$W ∈ R^{I×F} and H ∈ R^{F ×J}$,H列围绕K个质心聚集,那么问题公式:  \n",
    "  \n",
    "  $$\\underset{W ∈ R^{I×F}and H ∈ R^{F ×J}and S ∈ Z^{k ×J}and H ∈ M^{F ×K}}{min}{||X-WH||_F^2 +\\lambda||H-MS||_F^2}$$  \n",
    "    \n",
    "      \n",
    "  $$s.t. W\\geq0,H\\geq0 \\;\\;\\;||S(:,j)||_0=1\\;\\;S(k,j)\\in\\{0,1\\}$$    \n",
    "    \n",
    "其中第二项是在H列上强制执行先验聚类的K均值罚分，而调整参数λ≥0可平衡数据保真度和先验聚类。 该表述允许最大后验（MAP）解释,如果X = W（MS + E2）+ E1，则数据域噪声E1和潜域噪声E2均从i.i.d获得。  （独立且均匀分布）高斯分布且彼此独立，分别具有方差$σ_1^2和σ_2^2，并且λ=\\frac{σ_1^2}{σ_2^2}$。假设（W，H）满足NMF可识别性条件，并且E1可以忽略不计（即NMF精确），则H将被准确回收，因此聚类也将成功。 当然，在实践中，因式分解模型（DR）将是不完善的，因此聚类损失将有助于获得更准确的因式分解，从而更好地进行聚类。\n",
    "  请注意，此方法将K和F解耦，因为它使用聚类惩罚而不是RKM使用的硬约束H = MS，这会导致在F <K时出现秩不足.从MAP的角度来看，公式（9）看起来很直观且动机很好，但是有一些警告。 接下来讨论这些。    \n",
    "      \n",
    "        \n",
    "<br>        \n",
    "      \n",
    "设计注意事项：  \n",
    "第一个问题是扩展。 在（9）中，对H的正则化隐含地倾向于小范数H，因为如果H小，则只需取M = 0即可。 另一方面，第一个项相对于H的缩放不变，只要在W中得到补偿即可。为防止这种情况，我们引入W的范数正则化，则有：  \n",
    "$$\\underset{W ∈ R^{I×F}and H ∈ R^{F ×J}and S ∈ Z^{k ×J}and H ∈ M^{F ×K}}{min}{||X-WH||_F^2 +\\lambda||H-MS||_F^2 +\\eta||W||_F^2}$$                \n",
    "$$s.t. W\\geq0,H\\geq0 \\;\\;\\;||S(:,j)||_0=1\\;\\;S(k,j)\\in\\{0,1\\}$$    \n",
    "  \n",
    "  请注意，如果需要，可以使用$||W||_1$代替$||W||_F^2$来鼓励稀疏性。  \n",
    "  另一个考虑因素更加微妙。 在许多应用中，例如文档聚类，已经观察到[34]，[35]，相关系数或余弦相似度比欧几里德距离更适合聚类。 我们已经观察到，对于潜在聚类也是如此，这表示需要在潜在域中进行规范化。图3提供了确凿的证据，该图显示了Reuters-25718数据集中两个文档簇的潜在表示。 这些表示是使用F = 2由普通NMF提取的。在图3中，左侧的潜在表示很难聚类，尤其是靠近原点的那些，但是投影到单元2-范数球上之后（相当于使用 余弦相似度以聚类在左侧的点）聚类结构在右侧变得更加明显。  \n",
    "    \n",
    "   如果将K-means应用于数据域，则可以轻松地包含余弦相似性度量标准：通过预先使用其2-范数对数据列进行归一化，K-means有效地将余弦相似度用作距离度量。\n",
    "  但是，在我们的上下文中，由于H在每次迭代中都会发生变化，因此对于聚类部分的幼稚地采用余弦相似度会使事情变得复杂。 为了适应这一点，我们将问题重新表述如下。  \n",
    "    \n",
    "    \n",
    "  \n",
    "  引入对角矩阵D是至关重要的：它使我们能够将H的列固定到单位2范数球上，而不会损失分解模型的一般性。\n",
    "   （11）中的公式可以推广到张量曲面模型。 考虑一个三向张量X∈RI×J×L，其加载因子为A∈RI×F，B∈RJ×F，C∈RL×F。\n",
    "   假设A的行可以聚类为K组，则联合张量分解和A模式潜在聚类问题可以表示为  \n",
    "     \n",
    " 正规化项kBk2F和kCk2F在那里控制缩放。 如果希望在更多模式下执行潜在聚类，则范数正则化也可以用K表示B和/或C模式的正则化来代替。 对于没有K-means正则化的模式，具有范数正则化仍然很重要。值得一提的有趣一点是，如果采用VolMin作为分解标准，则不必引入D，因为VolMin已经将H（:, j）限制在unit（1-）范数球上。 我们也不需要用W的范数进行正则化，因为在这种情况下W的缩放比例不能是任意的，因此得出   \n",
    "    \n",
    " <br>     \n",
    "        \n",
    " 扩展：联合因素分析和子空间聚类:  \n",
    " 除了考虑问题（11）-（13）之外，我们还考虑了它们的子空间聚类对应项，即用K均值惩罚替换为子空间聚类惩罚。 子空间聚类处理来自子空间联合的数据[36]。具体来说，考虑X（:, j）∈R（W（:, Fk））  \n",
    "   \n",
    "   许多子空间聚类公式，例如[37]，[38]中的公式，都可以集成到我们的框架中，但是我们将自己限于简单的K-子空间聚类，并假设子空间K的数量和子空间维数{ri} Ki = 1 为简单起见而闻名。 以NMF和K-subspace联合聚类为例，我们可以将问题表达为  \n",
    "     \n",
    "   ### 优化算法\n",
    "   我们提供用于处理上一节中阐述的各种问题的算法。 基本思想是交替优化-将变量分解为小块，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
