{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度子空间聚类  \n",
    "  \n",
    "### 子空间聚类      \n",
    "\n",
    "* **什么是子空间？**    \n",
    "  \n",
    "  子空间：  \n",
    "     子空间指的是维度小于全空间的部分空间。所谓空间指的是带有一些特定性质的的集合，故子空间可以算是子集合。   \n",
    "            \n",
    "   <br>  \n",
    "     \n",
    "   线性空间（又称为向量空间）：  \n",
    "   设V是一个非空集合，P是一个数域，若：  \n",
    "   1、在V种定义了一种运算，称为加法，即对V中任意两个元素$\\alpha$和$\\beta$，都按某一法则运算后，都与V中唯一一个确定元素$\\alpha +\\beta$对应  \n",
    "   2、在P与V之间定义一种运算；即对V中任意元素$\\alpha$，p中任意一元素K,两者之间按运算后结果，都与V中唯一一个确定运算$K\\alpha$对应  \n",
    "   3、在1，2中的加法和乘法要满足  \n",
    "   $\\qquad$1、$\\alpha +\\beta=\\beta + \\alpha \\;\\;$  \n",
    "   $\\qquad$2、$\\alpha +（\\beta+\\gamma）=(\\beta + \\alpha)+\\gamma \\;\\;$  \n",
    "   $\\qquad$3、$ 0\\in V \\;\\; \\alpha \\in V \\;\\; 0+\\alpha=\\alpha \\;\\;\\; $  \n",
    "   $\\qquad$4、对任意$ -\\alpha \\in V $都存在$ \\beta \\in V \\;\\;$使$\\alpha +\\beta=0 \\qquad$  \n",
    "   $\\qquad$5、对P中单元1，有$1\\alpha=\\alpha \\;\\;(\\alpha \\in V)$  \n",
    "   $\\qquad$6、对任意$k，l \\in P ，\\alpha \\in V $有$(kl)\\alpha=k（l\\alpha）$   \n",
    "   $\\qquad$7、对任意$k，l \\in P ，\\alpha \\in V $有$(k+l)\\alpha=k\\alpha +l\\alpha$  \n",
    "   $\\qquad$8、对任意$k \\in P ，\\alpha ,\\beta \\in V $有$k(\\alpha+\\beta)=k\\alpha + k\\beta$\n",
    "     \n",
    "   满足上述条件之后，则称**V是数域P上的一个线性空间**。  \n",
    "     \n",
    "   V中元素称为向量，V的零元素称为零向量。P称为线性空间的基域，当P是实数域时，V称为实线性空间，当P是复数域时，V称为复线性空间。  \n",
    "     \n",
    "   以上定义得：V是一个线性空间  \n",
    "     \n",
    "   <br>  \n",
    "     \n",
    "   线性相关：  \n",
    "   如果V是一个线性空间，如果存在不全为0的系数$c_1,c_2,……，c_n \\; \\in F $ 使得$c_1V_1+c_2V_2+……+c_nV_n=0 $那么，线性空间V中的向量$v_1,v_2,……，v_n$称为线性相关的。反之称为线性无关的。  \n",
    "     \n",
    "   <br>  \n",
    "    \n",
    "   线性子空间：  \n",
    "   设W为向量空间V的一个非空子集，若W在V的加法即标量乘法下是封闭的，且零向量$0\\in W$,就称W为V的线性子空间。   \n",
    "     \n",
    "   <br>  \n",
    "     \n",
    "   线性映射：  \n",
    "   设定由V到W的线性变换或‘线性映射’\n",
    "     \n",
    "   <br>  \n",
    "     \n",
    "   非线性映射：\n",
    "     \n",
    "   <br>  \n",
    "     \n",
    "   线性映射子空间：  \n",
    "     \n",
    "   <br>  \n",
    "    \n",
    "   非线性映射子空间：\n",
    "     \n",
    "  \n",
    "   \n",
    " <br>   \n",
    "  \n",
    "多年来，人们发展了许多线性子空间聚类方法。一般来说，这些方法包括两个步骤：第一步也是最关键的一步是估计每对数据点的亲和力，以形成亲和力矩阵；第二步使用该亲和力矩阵应用归一化割集或谱聚类。由此产生的方法可以大致分为三类：因子分解方法、基于高阶模型的方法和基于自表达的方法。   \n",
    "          \n",
    " <br>         \n",
    "          \n",
    "  \n",
    "### 非线性映射    \n",
    "\n",
    "   采用编码器，把数据进行非线性映射。  \n",
    "   **这篇文章的思想是：用非线性映射，对数据进行变换，再对变换后的数据进行子空间聚类。**\n",
    "\n",
    "<br>    \n",
    "\n",
    "\n",
    "  \n",
    "### 什么是子空间聚类？    \n",
    "  \n",
    "<br>     \n",
    "    \n",
    "###  Self-Expressiveness 在子空间聚类中的应用\n",
    "    \n",
    "<br>  \n",
    "\n",
    "<br>\n",
    "  \n",
    "### Self-Expressiveness  \n",
    "  \n",
    "   从多个线性子空间$S\\{i\\} \\;\\;\\;  i=1,2,……,k \\quad$中获取数据点$X\\{i\\} \\;\\;\\; i=1,2,……,N \\quad$ （这里子空间，是未进行线性映射前的子空间，所以每个子空间，就代表了训练集的一个子集，每个子集表示一类的样本）   \n",
    "     \n",
    "   <br>  \n",
    "   \n",
    "   Self-Expressiveness性质：  \n",
    "   子空间中的一点，可以由同一子空间中其他点来线性表示。 X=XC    \n",
    "   \n",
    "   <br>\n",
    "     \n",
    "   X=XC ； 这里矩阵C,每列表示了数据之间的相关系数。这些相关系数体现了数据的聚类特性。对C进行范数要求，比如1范数，对C的要求为尽可能的多。聚类特性更明显。$C_{ij}\\neq 0$表示数据$x_i \\; x_j$可能在同一个子空间中（聚类中） ，且同时要求 $C_{ii} = 0$ 。对角元素为0,是为了让样本$x_i$可以由其他样本线性表示。假如可以让$C_{ii} \\neq 0$，那么线性相关时其他样本的系数为0就行了。\n",
    "     \n",
    "   <br>  \n",
    "   \n",
    "   同时要解释损坏数据则，Self-Expressiveness性质的数学表达式为：  \n",
    "   $\\underset{C}{min} \\;\\; ||c||_p +\\frac{C}{2}||X-XC||_F^2  \\quad s.t.(diag(C)=0)$   \n",
    "     \n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "\n",
    "\n",
    "### 网络结构  \n",
    "\n",
    "  让神经网络模拟 Self-Expressiveness  性质。   \n",
    "    \n",
    "  编码器（$x \\rightarrow z$  参数$\\theta_e$ ）,Self-Expressiveness层($Z \\rightarrow ZC$ 参数C）,解码器($ZC \\rightarrow \\hat{x}$ 参数$\\theta_d$)  \n",
    "    \n",
    " ![](img/2.PNG)     \n",
    "   \n",
    " <br>    \n",
    " \n",
    " 损失函数：  \n",
    "   \n",
    "   $L(\\theta)=\\frac{1}{2}||x-\\hat{X_\\theta}||_F^2 + \\lambda_1||\\theta_s||_p  + \\frac{\\lambda_2}{2} ||Z_{\\theta_e}-Z_{\\theta_e}\\theta_s||_F^2 \\quad s.t.(diag(\\theta_s)=0)$  \n",
    "         \n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "\n",
    "### 聚类\n",
    "   \n",
    "   获得C之后，拿去做谱聚类，进行切图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
