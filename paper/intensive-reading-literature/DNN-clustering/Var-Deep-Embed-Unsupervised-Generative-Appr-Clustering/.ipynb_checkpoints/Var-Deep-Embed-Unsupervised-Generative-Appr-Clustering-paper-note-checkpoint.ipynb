{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变分深度嵌入：一种无监督的生成聚类方法  \n",
    "   \n",
    "   \n",
    "### 摘要  \n",
    "聚类是机器学习和人工智能中最基础的任务。在这篇文章中我们提出变分深度嵌入（VaDE）。一种基于变分自编码器（VAE）的无监督生成聚类方法。  \n",
    "变分深度嵌入模型VaDE的数据生成使用混合高斯分布和深度神经网络。其中1、高斯混合分布选择了聚类模型，2、数据是从潜在空间的嵌入中生成的，3、深度神经网络把潜在嵌入编码为可观测的。  \n",
    "VaDE中的推断是通过一种变分的方法。另一种不同的神经网络用来把观测的数据解码为潜在嵌入。下界能够使用随机梯度来优化。  \n",
    "\n",
    "### 引言  \n",
    "总的来说：现有的聚类方法分为两类 ，1、基于相似性的聚类，2、基于特征的聚类  \n",
    "1、基于相似性的聚类  \n",
    "相似性模型是建立在距离基础上的。N * N的矩阵，测量了两两样本对的距离。  \n",
    "2、基于特征的聚类  \n",
    "基于特征的聚类，输入 是N * D的矩阵，N是样本数，D是特征维度数。  \n",
    "\n",
    "深度神经网络在各种机器学习领域中获得成功。深度神经网络的核心是学得好的特征。  \n",
    "  \n",
    "本文的动机：基于神经网络开发一个聚类模型，1、网络可以学到好的特征，好的特征可以捕捉到统计学上的数据结构 2、能够生成数据样本    \n",
    "  \n",
    "本文中提出了一种聚类框架 ，VaDE，结合了变分自编码器和高斯混合分布。VaDE模型通过使用高斯混合分布的神经网络来生成样本，f 1、一个聚类通过高斯混合分布来采集，2、潜在的表示z被采样 3、DNN把Z编码为可观测的样本x 。 此外 VaDE还优化一个解码器把x解码为Z。  \n",
    "  \n",
    "VaDE用先验的高斯混合分布代替单一的高斯分布。  \n",
    "  \n",
    "本文的主要贡献：  \n",
    "1、提出了无监督生成网络VaDE,结合了VAE和GMMM  \n",
    "2、提出了优化VaDE的方法，通过最大最小化ELBO,  \n",
    "3、VaDE能够生成高质量的样本对任意一个特定的聚类。且训练过程中没有任何有监督的信息。  \n",
    "  \n",
    "### 相关工作    \n",
    "   \n",
    "   好的特征在聚类任务中起到关键的作用。DEC是一个典型。但是DEC不能揭示潜在的数据结构。（DEC可以对样本去进行分类。但不能揭示数据的潜在结构。），这就导致DEC缺少可扩展性。例如生成样本。  \n",
    "     \n",
    "   深度生成模型最近吸引了大量的关注，由于它能通过深度神经网络来捕捉数据的真实分布，并且能够生成不增见过的样本。  \n",
    "  \n",
    "   GAN和VAE是近年来最成功的生成模型。他们都应用于无监督生成模型中，  \n",
    "     \n",
    "### 变分深度嵌入（VaDE）    \n",
    "\n",
    "![](img/1.PNG)\n",
    "  \n",
    "####  生成过程    \n",
    "因为变分深度嵌入（VaDE）是用于聚类的无监督深度生成方法。我们首先描述一下VaDE的生成过程。首先假设我们聚类的簇数是K类。一个样本x是按如下过程生成的。  \n",
    "1、选择一个聚类簇 $c\\text{~} cat(\\pi)$  \n",
    "2、选择一个潜在的向量$c\\text{~} N（\\mu_c,\\sigma_c^2I）$   \n",
    "3、选择一个样本x:  \n",
    "$\\qquad$ （a）如果x是二进制的  \n",
    "$\\qquad \\qquad$ **i.** 计算向量$\\mu_x=f(z;\\theta)$的期望  \n",
    "$\\qquad \\qquad$ **ii.** 抽样一个样本从$x\\text{~}Ber(\\mu_x）$的期望  \n",
    "  \n",
    "<br>  \n",
    "$\\qquad$ （b）如果x是连续值的  \n",
    "$\\qquad \\qquad$ **i.** 计算向量$[\\mu_x，\\sigma_x^2]=f(z;\\theta)$的期望  \n",
    "$\\qquad \\qquad$ **ii.** 抽样一个样本从$x\\text{~}N(\\mu_x，\\sigma_x^2)$的期望  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "$f(z;\\theta)$是神经网络，    \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "生成过程：  \n",
    "$P(X,Z,C)$这个联合概率中，有$x,c$条件独立于Z。  \n",
    "  \n",
    "$P(X,Z,C)=P(X,C|Z)P(Z)=P(X|Z)P(C|Z)P(Z)=P(X|Z) \\frac{P(C,Z)}{P(Z)}P(Z)=P(X|Z)P(Z|C)P(C)$   \n",
    "  \n",
    "即有：$P(X,Z,C)=P(X|Z)P(Z|C)P(C)$   \n",
    "  \n",
    "这其中的概率分别定义为；   \n",
    "  \n",
    "$P(C)=cat(C|\\pi)$  \n",
    "  \n",
    "$P(Z|C)=N(Z|\\mu_c,\\sigma_c^2I)$  \n",
    "  \n",
    "$P(x|Z)=Ber(X|\\mu_x) \\quad or \\quad N(Z|\\mu_x,\\sigma_x^2I)$  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "<br>  \n",
    "\n",
    "###  变分下界  \n",
    "  \n",
    "$log P(x) =log \\int_Z \\sum_{C}P(X,Z,C) dZ$   \n",
    "  \n",
    "$\\qquad\\quad =log \\int_Z \\sum_{C}q(Z,C|X)\\frac{P(X,Z,C)}{q(Z,C|X)} dZ$  \n",
    "  \n",
    "$\\qquad\\quad =log E_{q(Z,C|X)}[\\frac{P(X,Z,C)}{q(Z,C|X)}]$   \n",
    "  \n",
    "$\\qquad\\quad \\geq E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}] \\qquad \\text{Jenson不等式}$   \n",
    "   \n",
    "所以 log P(x) 的下界ELBO为：$E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}] $ 。  \n",
    "  \n",
    "$q(Z,C|X)$是后验概率，我们让它接近真实的后验概率$q_{true}(Z,C|X)$   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "**根据变分自编码器的理论：要达到上诉目标，我们只需要最大化ELBO公式就可以了。**  \n",
    "  \n",
    "对后验概率$q(Z,C|X)$，我们把它假设为一个简单的分布。即条件独立的分布。  \n",
    "  \n",
    "$$q(Z,C|X)=q(Z|X)q(C|X)$$  \n",
    "  \n",
    "那么我们的下界公式为：  \n",
    "  \n",
    "$ELBO=E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}]$  \n",
    "  \n",
    "$\\qquad\\;\\;=E_{q(Z,C|X)} log [\\frac{P(X|Z)P(Z|C)P(C)}{q(Z|X)q(C|X)}]$   \n",
    "  \n",
    "$\\qquad\\;\\;=E_{q(Z,C|X)}  [logP(X|Z) +logP(Z|C)+logP(C)-logq(Z|X)-logq(C|X)]$    \n",
    "  \n",
    "现在观察这个式子， 采样操作使用重参数技巧采样，且由于先前的假设，从q(Z,C|X)采样变为分别从q(Z|X)和q(C|X)采样。   \n",
    "  \n",
    "**我们观察到各个项中，只有q(C|X)我们是不知道一般形式的。那么对q(C|X)应该怎么办？**     \n",
    "\n",
    "<br>  \n",
    "  \n",
    "ELBO的一种变形方式是上面这种形式。我们还有另一种变形方式。  \n",
    "  \n",
    "$ELBO=E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}]$  \n",
    "  \n",
    "$\\qquad\\;\\;=\\int_z \\sum_C q(z|x)q(c|x) [log\\frac{P(X|Z)P(Z)}{q(Z|X)} +log \\frac{p(C|Z)}{q(C|X)}]dz$   \n",
    "  \n",
    "$\\qquad\\;\\;=\\int_z  q(z|x) log\\frac{P(X|Z)P(Z)}{q(Z|X)}dz -\\int_z q(z|x)D_{KL}(q(C|X)||p(C|Z)dz$    \n",
    "\n",
    "<br>\n",
    "  \n",
    "从这种变形中可以看出，最大化ELBO，应该让$D_{KL}(q(C|X)||p(C|Z) \\equiv 0$ ， 所以有：  \n",
    "  \n",
    "$$q(C|X)=p(C|Z)=\\frac{P(Z|C)P(C)}{\\sum_{c'=1}^K P(Z|c')P(c')}$$   \n",
    "\n",
    "<br>  \n",
    "\n",
    "<br>\n",
    "  \n",
    "由此可以得到$q(C|X)$的表达式：$q(C|X)=\\frac{P(Z|C)P(C)}{\\sum_{c'=1}^K P(Z|c')P(c')}$带回第一种变形。  \n",
    "  \n",
    "**至此我们知道了ELBO第一种变形公式中，所有项的一般表达式。**   \n",
    "  \n",
    "$ELBO=E_{q(Z,C|X)}  [logP(X|Z) +logP(Z|C)+logP(C)-logq(Z|X)-logq(C|X)]$   \n",
    "  \n",
    "**现在我们可以使用，随机变分推断：MCMC采样+重参数，求梯度。$\\Rightarrow$ 求出各个参数。**  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "\n",
    "**训练完了之后：聚类分配可以通过公式$q(C|X)=\\frac{P(Z|C)P(C)}{\\sum_{c'=1}^K P(Z|c')P(c')}$获得。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>   \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "<br> \n",
    " \n",
    "  \n",
    "<br>  \n",
    "\n",
    "\n",
    "\n",
    "## 总结    \n",
    "  \n",
    "  网络模型：  \n",
    "    \n",
    "![](img/1.PNG) \n",
    "\n",
    "<br>  \n",
    "  \n",
    "VaDE模型：为了达到聚类效果，加入了类别信息（GMM模型）(在VAE中是设所有样本都是从一个高斯分布Z中采样转化过来的。但是在VaDE中我们的假设是：先选择类别C,再选择类别C对应的，高斯Z,再把Z的采样转化为对应类别的样本 )。  \n",
    "  \n",
    "这个生成过程是：X，Z，C的联合概率  \n",
    "   \n",
    "$P(X,Z,C)$这个联合概率中，有$x,c$条件独立于Z。  \n",
    "  \n",
    "$P(X,Z,C)=P(X,C|Z)P(Z)=P(X|Z)P(C|Z)P(Z)=P(X|Z) \\frac{P(C,Z)}{P(Z)}P(Z)=P(X|Z)P(Z|C)P(C)$   \n",
    "  \n",
    "即有：$P(X,Z,C)=P(X|Z)P(Z|C)P(C)$     \n",
    "\n",
    "\n",
    "其中：  \n",
    "\n",
    "$P(C)=cat(C|\\pi)  \\qquad \\text{假设样本类别所服从的分布}$  \n",
    "  \n",
    "$P(Z|C)=N(Z|\\mu_c,\\sigma_c^2I) \\qquad \\qquad \\text{为每个类别C,假设一个分属各个类别的具体正态分布（不同类别参数）}\\mu_c,\\sigma_c不同。$  \n",
    "  \n",
    "$P(x|Z)=\\quad N(Z|\\mu_x,\\sigma_x^2I) \\qquad (\\mu_x,\\sigma_x^2 =f(z;\\theta))$  \n",
    "  \n",
    "$P(Z|X)=\\quad N(Z|\\mu_z,\\sigma_z^2I) \\qquad (\\mu_z,\\sigma_z^2 =g(x;\\phi))$  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "目标是：$q(𝑍,𝐶|𝑋)$ 是后验概率，我们让它接近真实的后验概率$𝑞_{𝑡𝑟𝑢𝑒}(𝑍,𝐶|𝑋)$  \n",
    "  \n",
    "使用变分推断：   \n",
    "\n",
    "$log p(x)=E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}] - KL(q(𝑍,𝐶|𝑋)||𝑞_{𝑡𝑟𝑢𝑒}(𝑍,𝐶|𝑋))$\n",
    " \n",
    " 使用Jenson等式发现： log P(x) 的下界ELBO为：$E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}] $   。  \n",
    "      \n",
    "  \n",
    "所以只要最大化ELBO这个下界就可以了。  \n",
    " \n",
    " $ELBO=E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}]$  \n",
    "  \n",
    "$\\qquad\\;\\;=E_{q(Z,C|X)} log [\\frac{P(X|Z)P(Z|C)P(C)}{q(Z|X)q(C|X)}]$   \n",
    "  \n",
    "$\\qquad\\;\\;=E_{q(Z,C|X)}  [logP(X|Z) +logP(Z|C)+logP(C)-logq(Z|X)-logq(C|X)]$   \n",
    "\n",
    "\n",
    "\n",
    "**我们观察到各个项中，只有q(C|X)我们是不知道一般形式的。**    \n",
    "\n",
    "**但是在另一种形式里有：**  \n",
    "  \n",
    "$ELBO=E_{q(Z,C|X)} log [\\frac{P(X,Z,C)}{q(Z,C|X)}]$  \n",
    "  \n",
    "$\\qquad\\;\\;=\\int_z \\sum_C q(z|x)q(c|x) [log\\frac{P(X|Z)P(Z)}{q(Z|X)} +log \\frac{p(C|Z)}{q(C|X)}]dz$   \n",
    "  \n",
    "$\\qquad\\;\\;=\\int_z  q(z|x) log\\frac{P(X|Z)P(Z)}{q(Z|X)}dz -\\int_z q(z|x)D_{KL}(q(C|X)||p(C|Z)dz$    \n",
    "\n",
    "从这种变形中可以看出，最大化ELBO，应该让$D_{KL}(q(C|X)||p(C|Z) \\equiv 0$ ， 所以有：  \n",
    "  \n",
    "$$q(C|X)=p(C|Z)=\\frac{P(Z|C)P(C)}{\\sum_{c'=1}^K P(Z|c')P(c')}$$    \n",
    "\n",
    "由此可以得到$q(C|X)$的表达式：$q(C|X)=\\frac{P(Z|C)P(C)}{\\sum_{c'=1}^K P(Z|c')P(c')}$带回第一种变形。   \n",
    "  \n",
    "**至此我们知道了ELBO第一种变形公式中，所有项的一般表达式。**   \n",
    "\n",
    "对这个公式：$ELBO=E_{q(Z,C|X)}  [logP(X|Z) +logP(Z|C)+logP(C)-logq(Z|X)-logq(C|X)]$   \n",
    " \n",
    "我们可以使用梯度下降法，来时ELBO 最大。  \n",
    "  \n",
    "求出的最大解，就是各个分布的参数了。  \n",
    "  \n",
    "训练完之后聚类分配可以通过$q(C|X)=\\frac{P(Z|C)P(C)}{\\sum_{c'=1}^K P(Z|c')P(c')}$获得。  \n",
    "  \n",
    "完成聚类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
