{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度表示和图像簇的联合无监督学习\n",
    "##### 摘要\n",
    "在本文中，我们提出了一种用于深度表示和图像聚类的联合无监督学习的循环框架。 在我们的框架中，聚类算法中的连续操作被表示为循环过程中的步骤，并堆叠在卷积神经网络（CNN）输出的表示形式之上。 在训练过程中，图像聚类和表示将同时更新：图像聚类在前向进行，而表示学习则在后向进行。 该框架背后的关键思想是，良好的表示形式有利于图像聚类，聚类结果可为表示学习提供监督信号。 通过将两个过程集成到具有统一加权三元组损失函数的单个模型中并对其进行端到端优化，我们不仅可以获得更强大的表示，而且可以获得更精确的图像簇。 大量实验表明，我们的方法在各种图像数据集上的图像聚类性能均优于最新技术。 此外，当转移到其他任务时，学得的表示法通常可以很好地实现  \n",
    "  \n",
    "### 介绍\n",
    "我们正在目睹视觉内容的爆炸式增长。 近年来，机器学习和计算机视觉的重大进步，尤其是通过深度神经网络的发展，都依赖于监督学习和大量带注释数据的可用性。\n",
    "   但是，手动标记数据是一个耗时，繁琐且通常很昂贵的过程。 为了更好地利用可用的未标记图像，聚类和/或无监督学习是一个有前途的方向。在这项工作中，我们旨在解决在统一框架中针对未标记图像的图像聚类和表示学习。 利用图像的聚类ID作为监督信号来学习表示是一个自然的想法，而这些表示又将有利于图像聚类  \n",
    "   从高层次来看，给出了ns个未标记图像的集合I = {I1，...，Ins}，用于学习图像表示和聚类的全局目标函数可以写为  \n",
    "   其中L（·）是损失函数，y表示所有图像的聚类ID，θ表示表示参数。 如果我们固定{y，θ}中的一个为固定值，则优化可以分解为两个交替的步骤：  \n",
    "     \n",
    "   直观地讲，（2a）可以转换为基于固定表示的常规聚类问题，而（2b）是标准监督的表示学习过程。  \n",
    "   在本文中，我们提出了一种在两个步骤之间交替进行的方法-给定当前的表示参数来更新聚类ID，给定当前的聚类结果来更新表示参数。 具体来说，我们使用凝聚聚类[16]对图像进行聚类，并通过卷积神经网络（CNN）的激活来表示图像。  \n",
    "   凝聚聚类（agglomerative clustering）指的是许多基于相同原则构建的聚类算法，这一原则是：算法首先声明每个点是自己的簇，然后合并两个最相似的簇，直到满足某种停止准则为止  \n",
    "   选择聚集聚类的原因有三点：1）它始于过度聚类，在尚未学会良好表示形式的情况下，从一开始就更加可靠。 从直觉上讲，使用随机权重初始化的CNN表示的聚类不是15147可靠的，但是最近的邻居和过度聚类是十个可接受的;  2）随着学习更好的表示，可以合并这些过多的群集；  3）集聚集群是一个循环过程，自然可以在循环框架中解释  \n",
    "   我们最终的算法非常直观。 我们从最初的过度集群开始，使用图像集群标签作为监控信号更新CNN参数（2b），然后合并集群（2a）并进行迭代，直到达到停止标准为止。 所提出的框架的结果如图1所示。最初，MNIST测试集（1万个样本）有1,762个聚类，其表示形式（图像强度）没有区别。 经过几次迭代，我们获得了17个clus ters和更多判别式表示。 最后，我们获得了10个聚类，这些聚类通过学习的表示法很好地分离，并且有趣的是，它们主要对应于数据集中的地面类别标签，即使以无监督的方式学习表示法也是如此。 总而言之，我们工作的主要贡献是：  \n",
    "   我们提出了一个简单但有效的端到端学习框架，以便从一个未标记的图像集中共同学习深度表示和图像簇；  2我们在循环框架中制定联合学习，其中聚集聚类的合并操作表示为正向传递，而CNN的表示学习则为反向传递；  3我们导出了一个损失函数来指导聚集聚类​​和深度表示学习，这使对两个任务的优化变得无缝。  4我们的实验结果表明，提出的框架优于以前的图像聚类方法，并学习了可以转移到其他任务和数据集的深层表示形式   \n",
    "     \n",
    "<br>   \n",
    "  \n",
    "    \n",
    "### 相关工作\n",
    "聚类聚类算法可以大致分为分层和分区方法[24]。 聚集聚类是一种分层聚类算法，它从许多小聚类开始，然后逐渐合并聚类[12、16、30]。 至于分区聚类方法，最著名的是K-means [36]，它使数据点与其最近的聚类中心之间的平方误差之和最小。 相关思路形成了许多方法的基础，例如期望最大化（EM）[7，37]，频谱聚类[40，47，61]和基于非负矩阵分解（NMF）的聚类[1，8，  60]。深度表示学习许多作品使用原始图像强度或手工制作的特征[9、18、19、23、42、50]与常规聚类方法相结合。 最近，在许多计算机视觉任务上，使用深度神经网络学习的表示形式都比手工设计的功能有了显着改进，例如图像分类[29、44、46、49]，物体检测[13、14、20、43]等 。但是，这些方法依赖于带有大量标记数据的监督学习来学习丰富的表示形式。许多工作致力于从未标记的图像数据中学习表示形式，一类方法可满足重建任务，例如自动编码器[21、28、33、41、53]，深度置信网络（DBN）[31]等。另一类技术是在为图像制作监督信号后学习判别表示， 然后对它们进行有针对性的微调，以用于下游应用[10，11，55]。 与我们的方法不同，这些先前工作中的虚构监督信号在表示学习期间不会更新。  \n",
    "组合探索了将图像聚类与表示学习相结合的许多作品。 在[51]中，作者建议使用堆叠式自动编码器学习无向亲和图的非线性嵌入，然后在嵌入空间中进行K均值以获得聚类。 在[52]中，使用了一个深的半NMF模型将输入分解为多个堆叠因子，并逐层初始化和更新。 使用顶层的表示法，实现了K均值以获得最终结果。 与我们的工作不同，它们不会共同优化表示学习和聚类。  \n",
    "为了更紧密地连接图像聚类和表示学习，[58]反复进行图像聚类和码本学习。 但是，他们通过SIFT功能[35]学习了密码本，并且没有学习深入的表示法。  Chen [2]并未使用手工制作的功能，而是使用DBN来学习表示，然后对DBN的输出进行了非参数最大余量聚类。 之后，他们根据聚类结果对DBN的顶层进行了微调。 在[56]中发现了关于联合优化两个任务的最新工作，作者在其中训练了用于集群的特定于任务的深度架构。 深度架构由稀疏编码模块组成，可以通过面向集群的丢失的反向传播对它们进行联合训练。 但是，他们使用稀疏编码来提取图像表示，而我们使用CNN。 我们没有根据softmax输出将聚类的数量固定为类别和预测标签的数量，而是基于学习的表示，使用聚集聚类来预测标签。 在我们的实验中，我们证明了我们的方法优于[56]。  \n",
    "  \n",
    "<br>  \n",
    "    \n",
    " ### 方法    \n",
    " 表示：  \n",
    " \n",
    " 我们用I = {I1，...，Ins}表示一个包含ns个图像的图像集。 此图像集的群集标签为y = {y1，...，yns}。  θ是CNN参数，从中我们可以从I获得深度表示X = {x1，...，xns}。给定预测的图像簇标签，我们可以学习深度表示和图像簇。\n",
    "   将它们组成nc簇C = {C1，...，Cnc}，其中Ci = {xk | yk = i，∀k∈1，...，ns}。  NiK是xi的Ks最近邻居，并且是Ci的Kc最近邻居簇的集合。 为方便起见，我们按与Ci的亲和力降序对聚类进行排序，以使最近的邻居argmaxC∈CtA（Ci，C）是第一个条目。 在此，A是一种测量两个聚类之间亲和力（或相似性）的函数。 我们在{θ，X，y，C}上添加上标t来引用它们在时间步t的状态。 我们用Y表示具有T个时间步长的序列{y1，...，yT}。  \n",
    "     \n",
    "     \n",
    "亲和力测度：  \n",
    "  \n",
    "首先，我们建立一个有向图G = <V，E>，其中V是对应于I的深层表示X的一组顶点，E是连接这些顶点的边的集合。我们定义与边缘集相对应的亲和力矩阵W∈Rns×ns。 从顶点xi到xj的权重定义为：  \n",
    "  \n",
    "  这种建立有向图的方法可以在许多以前的著作中找到，例如[62，64]。 在此，a和Ks是两个预定义的参数（它们的值在表2中列出）。  在为样本构造了有向图之后，我们在[62]中采用图度链接来测量簇Ci和Cj之间的亲和力，用A（Ci，Cj）表示。  \n",
    "    \n",
    "   \n",
    "循环框架:  \n",
    "\n",
    "我们的主要见解是，聚结聚类可以解释为一个递归过程，因为它可以在多个时间步长上合并聚类。 基于这种见识，我们提出了一个将图像聚类和表示学习过程相结合的递归框架。   \n",
    "\n",
    "如图2所示，在时间步t处，图像I首先被送入CNN以获取表示Xt，然后与先前的隐藏状态ht 1结合使用以预测当前的隐藏状态ht，即图像簇标签 在时间步t。 在我们的上下文中，时间步长t的输出为yt = ht。 因此，在时间步t  \n",
    "  \n",
    "其中fr是使用θt参数化的CNN提取输入I的深层表示Xt的函数，fm是用于基于Xt和ht 1生成ht的合并过程。  \n",
    "  \n",
    "在这项工作中，我们引入了部分展开策略，即，我们将整个T时间步分为多个时段，并一次展开一个时段。 我们部分展开的直观原因是，开始时CNN的表示不可靠。 我们需要更新CNN参数，以获取用于以下合并过程的更多判别式表示。 在每个周期中，我们合并多个簇，并在周期结束时更新CNN参数以进行固定数量的迭代。 一个极端的情况是每个周期一个时间步长，但是它涉及到CNN参数的过高约会，因此非常耗时。 因此，在我们的方法中，每个参数的时间步数（以及每个周期合并的簇数）由参数确定。 我们将在第二节中对此进行详细说明。  3.6。    \n",
    "  \n",
    "    \n",
    " <br>  \n",
    "  \n",
    "目标函数：  \n",
    "   \n",
    "   在我们的循环框架中，我们累积了所有时间步长的损失，公式为：  \n",
    "     \n",
    "       \n",
    "       \n",
    "   y0将每个图像作为一个簇。在时间步t，我们找到两个要合并的簇，给定yt 1。 在传统的聚类聚类中，两个聚类由5149确定，以找到所有成对聚类的最大亲和力。在本文中，我们引入了一个准则，该准则不仅考虑两个聚类之间的亲和力，还考虑聚类周围的局部结构。 假设从ytt 1到yt，我们合并了一个群集Cti及其最近的邻居。则在时间步长t处的损失是负亲和力的组合，  ：  \n",
    "   \n",
    "     \n",
    "       \n",
    "   其中λ权重（7a）和（7b）。 请注意，yt，ytt 1和θt未在右侧明确显示，但它们通过图像簇标签和簇之间的亲和力确定损耗：在上述方程式的右侧，有两个术语：1）（7a）度量聚类Ci与它的最近邻居之间的亲和力，它遵循常规的聚类聚类；  2）（7b）测量了Ci与其最近邻居簇的亲和力与Ci与其其他邻居簇的亲和力之间的差异。 该术语考虑了局部结构。 参见第二节。  3.5.1进行详细说明。 很难同时导出使方程式中的总损耗最小的最优{y1，...，yT}和{θ1，...，θT}。  （6）。 如上所述，我们在循环过程中进行迭代优化。 我们将T时间步长划分为P个部分展开的时间段。 在每个周期中，我们固定θ并在前向遍历中搜索最优y，然后在后向遍历中，给定最优y来推导最优θ。 以下各节将详细说明   \n",
    "     \n",
    "       \n",
    " 前向算法：  \n",
    " 在第p个第（p∈{1，...，P}）部分展开的周期的前向通过中，我们将θ固定为θp来更新聚类标签，并且周期p的总损失为：  \n",
    " \n",
    " 其中Yp是周期p中的图像标签序列，[tsp，tep]是周期p中的相应时间步长。 为了进行优化，我们遵循类似于常规聚集聚类的贪婪搜索。 从时间步tsp开始，它找到一个群集及其最近的邻居进行合并，因此在所有可能的群集对上将Lt最小化  \n",
    "   \n",
    " 我们提供一个玩具示例来解释为什么我们使用（7b）术语。 如图所示，通常是在某些区域中群集密集，而在另一些区域中群集稀疏的情况  \n",
    " 在传统的聚类聚类中，每次没有聚类所在的地点时，它将选择两个亲和力最大（或损失最小）的聚类。 在这种特定情况下，它将选择群集Cb及其最近的邻居进行合并。 相反，如图3（b）所示，我们的算法通过添加（7b）会发现簇Ce，因为它不仅靠近它的最近邻居，而且也距离它的其他邻居相对较远，即， 局部结构被视为围绕一个集群。 引入（7b）的另一个优点是，它将允许我们按照三元组来记下损失，如下所述。  \n",
    "   \n",
    "     \n",
    " 后向算法： \n",
    " 在第p部分展开阶段的前向传递中，我们合并了许多聚类。 令最佳图像聚类标记的序列由Yp ∗ = {yt ∗}给出，向前合并的聚类由{[Ct ∗，N Kc Ct ∗ [1]]}表示，t∈{  tsp，...，tep}。 在后向通道中，我们旨在推导最佳θ以最大程度地减少前向通道中产生的损耗。\n",
    "   由于当前期间的聚类取决于所有先前时期的聚类结果，因此我们累积了所有p个时期的损失，即  \n",
    "     \n",
    "      \n",
    "        \n",
    "         \n",
    "          ‘ \n",
    "           \n",
    "##### 优化  \n",
    "给定一个具有ns个样本的图像数据集，我们假设所需聚类的数量n * c是聚类中的标准然后，我们可以将T = ns n * c个时间步长建立一个循环过程，首先将每个样本视为一个簇。但是，这种初始化使优化变得很费时，尤其是在数据集包含大量样本的情况下。为了解决这个问题，我们首先可以运行快速聚类算法来获得初始集群。在这里，我们采用[63]中提出的初始化算法与他们的实验结果进行公平比较。\n",
    "   注意，也可以使用其他类型的初始化，例如    K均值。 基于文献[63]中的算法，我们获得了多个簇，每个簇包含几个样本（实验中平均约4个）。给定这些初始聚类，我们的优化算法将学习深度表示和聚类。 该算法在Alg中概述。  1。\n",
    "   在每个部分展开的周期中，我们执行前向和后向遍历以分别更新y和θ。 具体来说，在前向传递中，我们在每个时间步合并两个聚类。 在后退遍历中，我们运行约20个纪元来更新θ，并且亲和力矩阵W也会根据新表示进行更新。 第p个周期的持续时间为np = ceil（η×nsc）个时间步长，其中nsc是当前周期开始时的簇数，而η是称为解开率的参数，用于控制时间步长的数量。\n",
    "   η越小，我们更新θ的频率越高  \n",
    "     \n",
    "   \n",
    "###### 实验   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
