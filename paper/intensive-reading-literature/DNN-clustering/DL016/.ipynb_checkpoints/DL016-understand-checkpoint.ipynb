{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从隐藏的特征学习：联合因素分析和潜在聚类\n",
    "\n",
    "\n",
    "### 主要思路\n",
    "对数据降维很有必要，通常你情况下，在预处理阶段实现对数据的降维操作。在后续训练过程中实现聚类过程。  \n",
    "  \n",
    " 通常在聚类和分类之前应用降维（DR）。 矩阵和张量分解（或因子分析）分别在矩阵和张量数据的DR中起着重要作用  \n",
    "   \n",
    "     \n",
    "在降维的因素分析和灾难恢复时所要考虑的问题：  \n",
    "1、因素分析时：使用什么样类型的因子来达到所要求的降维后数据表达形式。为后续聚类提供有效帮助。如果数据存在某个因子，且这个因子降维后的数据存在簇结构。那么拟合这个因子就能揭示潜在的簇结构。  \n",
    "  \n",
    "  \n",
    "2、降维时，选用什么样的先验信息，决定了降维后的数据表现形式。使用先验信息能够抵御噪声和建模错误。常用的先验信息：矩阵和张量分解的各种约束和正则化先验，例如稀疏性，平滑度，单峰性，总变化和非负性  \n",
    "\n",
    "这篇文章选用了潜在聚类结构做先验信息。因为降维数据通常在聚类任务中产生更好的性能。所以可以用潜在的聚类结构做降维的先验信息，而数据的聚类结构在降维后的数据域中相对于数据域更为明显。  \n",
    "  \n",
    "  <br>\n",
    "  \n",
    "了清楚地看到这一点，请考虑矩阵分解模型X = WH，其中X的每一列代表一个数据点，而H的对应列是其潜在表示。 考虑X的前两列之间的平方距离  \n",
    "$$d_1\\;=\\;||X（：，1）−X（：，2）||_2^2=[（H（：，1）−H（：，2）]^TW^TW[H（：，1）−H（：，2））]$$\n",
    "     \n",
    "      \n",
    "  潜在域距离$d_2\\;=\\;||H（：，1）−H（：，2）||_2^2=[（H（：，1）−H（：，2）]^T[H（：，1）−H（：，2））]$      \n",
    "        \n",
    "      \n",
    " 注意矩阵$W^TW$如何权衡潜在域距离以产生数据域距离  \n",
    "     \n",
    "       \n",
    "   可以看到聚类结构：$d_1,受W^TW$影响，潜在数据域距离$d_2$  W用作NMF的正则化–本质上，它迫使尺寸减小的表示在远处（接近）。 如果高维向量在数据域中较远（分别接近），则为潜在域。 然而，数据域距离和潜域距离不必彼此成正比 ，加上W正则化项  \n",
    "     \n",
    "       \n",
    "### 解决问题的方法  \n",
    "  设：$X≈WH∈R^{I×J}$ ，对于一些基于元素的非负数$W ∈ R^{I×F} and H ∈ R^{F ×J}$,H列围绕K个质心聚集,那么问题公式:\n",
    "  \n",
    "$$\\underset{W ∈ R^{I×F}and H ∈ R^{F ×J}and S ∈ Z^{k ×J}and H ∈ M^{F ×K}}{min}{||X-WH||_F^2 +\\lambda||H-MS||_F^2 +\\eta||W||_F^2}$$                \n",
    "$$s.t. W\\geq0,H\\geq0 \\;\\;\\;||S(:,j)||_0=1\\;\\;S(k,j)\\in\\{0,1\\}$$   \n",
    "  \n",
    "    \n",
    "理解：  \n",
    "$||X-WH||_F^2$ 做降维；其中H是降维后的数据表示形式，例如$X_{7\\times3}=W_{7\\times4}H_{4\\times 3}\\;\\;\\;\\;\\;$    其中X的每一列代表一个数据点，而H的对应列是其潜在表示;那么就把3个样本的（每个样本7个属性）变成了3个样本的（每个样本4个属性）的数据集。  \n",
    "  \n",
    "  <br>\n",
    " 在做降维的同时，我们求一下聚类：\n",
    " $\\lambda||H-MS||_F^2\\;\\;\\;\\;\\;$H是降维后的数据表示形式（每列代表一个数据，行代表属性）；；M是聚类中心（每列代表一类的聚类中心；k个聚类中心，共K列）；S是样本属于哪个聚类的指示矩阵（每列中只有一个1；总共K行，每列1的位置代表样本属于哪个聚类；每个数据不是0就是1）例如：$H_{4\\times3}=M_{4\\times k}S_{k\\times 3}\\;\\;\\;\\;\\;\\;\\;\\;M\\times S$后每列为H数据每列对应的聚类向量；所以H-MS的值应当越小越好；越小表明聚类越成功。\n",
    " \n",
    " \n",
    " \n",
    "   \n",
    " 样本数据，每列代表一个样本：$H= \\begin{pmatrix} 1 & 2 &3\\\\ 4 & 5&6 \\\\7&8 & 9\\\\ 10&11 & 12\\\\\\end{pmatrix} $  \n",
    "   \n",
    " 聚类中心矩阵(每列一个聚类向量)：$M= \\begin{pmatrix} K_1^1 &  K_1^2 & K_1^3\\\\ K_2^1 & K_2^2&K_2^3 \\\\K_3^1&K_3^2 & K_3^3\\\\\\end{pmatrix} $  \n",
    "      \n",
    "      \n",
    " 指示矩阵，每列代表对应属于哪个聚类（每列中共K行）：$S= \\begin{pmatrix} 1 & 0 &1&0\\\\ 0 & 1&0&1 \\\\0&0 & 0&0\\\\\\end{pmatrix} $   \n",
    "   \n",
    "     \n",
    "   MS代表了数据样本矩阵，对应样本的聚类中心矩阵，那么H-MS越小，则聚类越成功。  \n",
    "         \n",
    "    \n",
    "<br>      \n",
    "        \n",
    " 正则化项 $\\eta||W||_F^2$  用来规范降维；有很多降维方式，用这个正则化项选择有很好聚类效果的那个降维表示形式。      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_1^1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
