{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单的更好？再论用于无监督聚类的简单生成模型  \n",
    "  \n",
    "## 摘要  \n",
    "  \n",
    "  在本论文中我们提出一种方法同时完成聚类和特征学习。  \n",
    "    \n",
    "## 引言  \n",
    "  \n",
    "  传统的聚类算法k-means，GMM，如果数据的高维度过高则算法的性能会受很大影响。 **DNN可以有效的学得低维特征。** 现在不少论文都用神经网络提取特征，来完成聚类。如 DEC(Deep Embedding Clustering)。  \n",
    "    \n",
    " **本文利用生成模型：学习一个强有效的低维特征。**  \n",
    "   \n",
    "   \n",
    " $\\color{red}{\\text{实验结果表明：这个简单的模型结果更好，且不需要复杂的模型和逐层的预训练，相比较于那些最先进的方法。}}$    \n",
    "  \n",
    "<br>  \n",
    "\n",
    "## 用于聚类的深度生成模型  \n",
    " \n",
    " 本文的概率模型是基于，堆叠生成模型(M1+M2)基础之上的（M1+M2是用于半监督学的）。  \n",
    "   \n",
    " 使用线性编码器来学习数据特征：$\\hat{x}=g(x)$  \n",
    "   \n",
    "#### 无监督生成模型  \n",
    "  \n",
    "  使用两个变量来模拟数据，连续变量z,分类变量c。Z与C相互独立,生成模型为$P(X,Z,C)=P(C)P(Z)P(X|Z,C)$  \n",
    "    \n",
    "  $$p(c)=Cat(c|\\pi)$$   \n",
    "    \n",
    "  $$p(z)=N(z|0,1)$$   \n",
    "    \n",
    "  $$p(X|Z,C)=f(x,z,c,\\theta)$$   \n",
    "    \n",
    "其中 $Cat(c|\\pi)$ 是多项式分布。  \n",
    "  \n",
    "##### 无监督生成模型的训练变分下界  \n",
    "  \n",
    "![](img/2.PNG)    \n",
    "\n",
    "  \n",
    "<br>  \n",
    "\n",
    "### 最总的网络结构和目标函数  \n",
    "\n",
    "![](img/1.PNG)\n",
    "![](img/2.PNG)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
