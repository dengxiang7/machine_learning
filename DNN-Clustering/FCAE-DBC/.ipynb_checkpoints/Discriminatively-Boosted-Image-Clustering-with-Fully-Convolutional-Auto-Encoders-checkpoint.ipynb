{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结合全卷积自编码器与识别增强的深度网络聚类  \n",
    "\n",
    "![](img/DL0131.PNG)  \n",
    "  \n",
    "![](img/DL0137.PNG)  \n",
    "\n",
    "![](img/DL0138.PNG)  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "把编码器得到的特征，用T分布映射为一个分布的相似矩阵。对这个相似矩阵进行识别增强。其损失函数为KL散度  \n",
    " \n",
    " 增强的原理：  \n",
    "   \n",
    " 1、如果对t=0时刻任意j和j'，都有$s^0_{ij}=s^0_{ij'}$,那么在所有j和所有时刻都有$s^t_{ij}=1/K$   \n",
    "   \n",
    " 2、 如果存在一个$l$,使得$s^0_{il}=\\underset{j\\neq l}{max} s^0_{ij'}$，那么有$\\underset{t \\rightarrow \\infty}{lim} = s^0_{ij'}  =1 \\;\\;\\;if\\;\\;\\; j'=l   \\qquad\\qquad \\underset{t \\rightarrow \\infty}{lim} =  s^0_{ij'}  =0 \\;\\;\\;if\\;\\;\\; j'\\neq l $   \n",
    "         \n",
    "           \n",
    "  \n",
    "  ![](img/DL0132.PNG)\n",
    "  ![](img/DL0133.PNG)\n",
    "  ![](img/DL0134.PNG)  \n",
    "  \n",
    "  \n",
    "\n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "#### 流程  \n",
    "  \n",
    "1、首先训练预训练一个堆栈式全卷积自编码器。  \n",
    "  \n",
    "  其网络结构是：编码器部分是卷积层和池化层，解码器部分是反卷积层和反池化层。且为了加速训练速度，在每个卷积层和每个反卷积层操作之后都输都进行小批量标准化（Batch-normalization）。  \n",
    "  \n",
    "  最后只取解码器部分，加入我们的算法部分。（和传统的拿网络做提取特征，之后用特征进行聚类不同）。（这里还有一个操作是：用解码器提取特征，再用传统聚类得到聚类中心。这些聚类中心，是我们之后算法聚类中心的初始值）  \n",
    "    \n",
    "  为什么说和传统拿网络做特征提取不同？是因为之后我们整个算法的损失函数是包含网络参数的，对损失函数的参数进行优化，也是对网络的优化，整个结构是一体的相互关联，相互影响的。两个部分并不是独立的。  \n",
    "    \n",
    "  但这里有一个问题就是：在这个预训练部分就完成了传统的使用神网络做特征提取，传统聚类进行聚类的全部工作了。也就是说我们牺牲了时间耗费，用来提升聚类精度。  \n",
    "    \n",
    "<br>  \n",
    "   \n",
    "2、完成聚类识别的增强  \n",
    "  \n",
    "  1、用解码器提取特征，用T分布把样本特征转为分布矩阵$S_{ij}$。  \n",
    "    \n",
    "  2、对分布矩阵进行增强，得到增强分布$R_{ij}$。(增强原理上面有解释)  \n",
    "    \n",
    "$\\quad\\quad$这里增强的过程是：  \n",
    "  \n",
    "  $\\quad\\quad\\quad\\quad$在每一个大的学习周期里：求出$S_{ij}$，再用$S_{ij}$，求出$R_{ij}$。上一次迭代产生的网络，能在本次周期内产生更好的特征，所以这个更好的特征，   \n",
    "  $\\quad\\quad\\quad\\quad$ 有利于在本次周期产生更好的聚类结果。（正确聚类结果不是在一次迭代中就能完全出现的。所以需要多次的大周期进行学习，  \n",
    "  $\\quad\\quad\\quad\\quad$ 以确保能尽可能多的包含正确聚类样本）   \n",
    "  \n",
    "    \n",
    "  $\\quad\\qquad\\quad\\qquad\\quad\\qquad$用小批量样本重复多次迭代：的使用KL散度让 $S_{ij}=R_{ij}$，每一次都使$S_{ij}=R_{ij}$完成网络的迭代，使这次迭代中的正确聚类结果，    \n",
    "  $\\quad\\qquad\\quad\\qquad\\quad\\qquad$能【促进网络产生好的特征提取结果】的出现。而聚类识别增强，就相当于放大了这种促进作用   \n",
    "  \n",
    "  \n",
    "  $\\quad\\quad\\quad\\quad$这里当大的学习周期$t\\rightarrow \\infty$时，或者收敛时。$S^t_{ij}$里t时刻样本分配概率为在初始时刻$S^0_{ij}$的概率增强   \n",
    "    \n",
    "<br>  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "* 联合优化的目标函数：  \n",
    "  \n",
    " ![](img/DL0136.PNG)  \n",
    "   \n",
    "  其中Z为： $Z=f_{\\theta_e}(X)$ 。  \n",
    "    \n",
    "  所以对Z的更新就是对网络的调整。\n",
    "  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "#### 可能得疑惑  \n",
    "  \n",
    "* 识别加强有什么用？  \n",
    "    \n",
    "$\\qquad$t=0时刻最大概率得最大值，在$t=\\infty$时加强到接近1，两者得效果不是一样吗？那加强的意义何在呢？  \n",
    "  \n",
    "<br>  \n",
    "  \n",
    "* 解答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
